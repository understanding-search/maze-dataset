{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable, Any\n",
    "import json\n",
    "import random\n",
    "\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from muutils.errormode import ErrorMode\n",
    "from muutils.misc import shorten_numerical_to_str\n",
    "\n",
    "from maze_dataset.tokenization import (\n",
    "    MazeTokenizerModular,\n",
    "    _TokenizerElement,\n",
    "    MazeTokenizer,\n",
    "    TokenizationMode,\n",
    "    CoordTokenizers,\n",
    "    PromptSequencers,\n",
    "    AdjListTokenizers,\n",
    "    PathTokenizers,\n",
    "    TargetTokenizers,\n",
    "    StepSizes,\n",
    "    StepTokenizers,\n",
    "    EdgePermuters,\n",
    "    EdgeGroupings,\n",
    "    EdgeSubsets,\n",
    ")\n",
    "\n",
    "import maze_dataset.tokenization as md_tokenization\n",
    "\n",
    "from maze_dataset import (\n",
    "    VOCAB,\n",
    "    VOCAB_LIST,\n",
    "    VOCAB_TOKEN_TO_INDEX,\n",
    "    LatticeMazeGenerators,\n",
    "    MazeDataset,\n",
    "    MazeDatasetConfig,\n",
    "    SolvedMaze,\n",
    ")\n",
    "\n",
    "from maze_dataset.plotting import MazePlot\n",
    "\n",
    "from maze_dataset.util import equal_except_adj_list_sequence\n",
    "\n",
    "from maze_dataset.utils import all_instances\n",
    "\n",
    "from maze_dataset.tokenization.all_tokenizers import (\n",
    "    get_all_tokenizers, \n",
    "    MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `MazeTokenizerModular` Initialization and Structure\n",
    "\n",
    "Initialiation can be done vai the default constructor or via `MazeTokenizerModular.from_legacy`. The latter is useful for converting a legacy `MazeTokenizer` into its equivalent `MazeTokenizerModular`.\n",
    "\n",
    "Most of the API for these tokenizers is contained in the `MazeTokenizerModular` class. The only time when users need to interact with the internal components of a `MazeTokenizerModular` is when initializing a non-default tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_default: MazeTokenizerModular = MazeTokenizerModular()\n",
    "mt_ctt: MazeTokenizerModular = MazeTokenizerModular.from_legacy(TokenizationMode.AOTP_CTT_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objects composing `MazeTokenizerModular` are all instances of `_TokenizerElement`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'maze_dataset.tokenization.maze_tokenizer.CoordTokenizers._CoordTokenizer'>\n",
      "<class 'maze_dataset.tokenization.maze_tokenizer.EdgeGroupings._EdgeGrouping'>\n",
      "<class 'maze_dataset.tokenization.maze_tokenizer.EdgePermuters._EdgePermuter'>\n",
      "<class 'maze_dataset.tokenization.maze_tokenizer.EdgeSubsets._EdgeSubset'>\n",
      "<class 'maze_dataset.tokenization.maze_tokenizer.AdjListTokenizers._AdjListTokenizer'>\n",
      "<class 'maze_dataset.tokenization.maze_tokenizer.TargetTokenizers._TargetTokenizer'>\n",
      "<class 'maze_dataset.tokenization.maze_tokenizer.StepSizes._StepSize'>\n",
      "<class 'maze_dataset.tokenization.maze_tokenizer.StepTokenizers._StepTokenizer'>\n",
      "<class 'maze_dataset.tokenization.maze_tokenizer.PathTokenizers._PathTokenizer'>\n",
      "<class 'maze_dataset.tokenization.maze_tokenizer.PromptSequencers._PromptSequencer'>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([str(elem) for elem in _TokenizerElement.__subclasses__()]))\n",
    "assert all(issubclass(elem, _TokenizerElement) for elem in _TokenizerElement.__subclasses__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within a tokenizer, these `_TokenizerElement`s are structured in a nested dataclass tree. The tree is slightly different depending on the particular options selected. Below are shown 3 different tree representations of `mt_default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AOTP `TokenizerElement` Structure:\n",
      "\n",
      "MazeTokenizerModular\n",
      "\t_PromptSequencer\n",
      "\t\t_CoordTokenizer\n",
      "\t\t_AdjListTokenizer\n",
      "\t\t\t_EdgeGrouping\n",
      "\t\t\t_EdgeSubset\n",
      "\t\t\t_EdgePermuter\n",
      "\t\t_TargetTokenizer\n",
      "\t\t_PathTokenizer\n",
      "\t\t\t_StepSize\n",
      "\t\t\t_StepTokenizer\n",
      "\n",
      "Default tokenizer elements:\n",
      "\n",
      "MazeTokenizerModular\n",
      "\tAOTP\n",
      "\t\tUT\n",
      "\t\tAdjListCoord\n",
      "\t\t\tUngrouped\n",
      "\t\t\tConnectionEdges\n",
      "\t\t\tRandomCoords\n",
      "\t\tUnlabeled\n",
      "\t\tStepSequence\n",
      "\t\t\tSingles\n",
      "\t\t\tCoord\n",
      "\n",
      "`MazeTokenizerModular` structure with all fields:\n",
      "\n",
      "MazeTokenizerModular:\n",
      "  AOTP:\n",
      "    adj_list_tokenizer:\n",
      "      AdjListCoord:\n",
      "        edge_grouping:\n",
      "          Ungrouped:\n",
      "            connection_token_ordinal: 1\n",
      "        edge_permuter:\n",
      "          RandomCoords: {}\n",
      "        edge_subset:\n",
      "          ConnectionEdges:\n",
      "            walls: false\n",
      "        post: true\n",
      "        pre: false\n",
      "        shuffle_d0: true\n",
      "    coord_tokenizer:\n",
      "      UT: {}\n",
      "    path_tokenizer:\n",
      "      StepSequence:\n",
      "        intra: false\n",
      "        post: false\n",
      "        pre: false\n",
      "        step_size:\n",
      "          Singles: {}\n",
      "        step_tokenizers:\n",
      "        - Coord: {}\n",
      "    target_tokenizer:\n",
      "      Unlabeled:\n",
      "        post: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nAOTP `_TokenizerElement` Structure:\\n')\n",
    "print(mt_default.tokenizer_element_tree(abstract=True))\n",
    "print(f'Default tokenizer elements:\\n')\n",
    "print(mt_default.tokenizer_element_tree())\n",
    "print(f'`MazeTokenizerModular` structure with all fields:\\n')\n",
    "print(yaml.dump(mt_default.tokenizer_element_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently no other constructor methods. To construct a `MazeTokenizerModular` with other `TokenizerElement`s besides those available via `from_legacy`, the standard constructor with all parent `TokenizerElement`s in the tree must be used. Some `TokenizerElement`s also contain their own initialization arguments, most of which are `boolean`-typed. The most common arguments across all `TokenizerElement`s are named `pre`, `intra`, and `post`, which all control the option to add delimiter tokens to that part of the output. Other args are more specialized; see the class docstrings for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary\n",
    "\n",
    "All instances of `MazeTokenizerModular` uses a static vocabulary `VOCAB`, which is one of the main functional differences from `MazeTokenizer`. Direct access to the static vocabulary can be made through 3 constants:\n",
    "- `VOCAB`\n",
    "  - Extension of the `SPECIAL_TOKENS` dataclass\n",
    "  - Supports direct property attribution\n",
    "- `VOCAB_LIST: list[str]`\n",
    "  - Contains the vocabulary in a list\n",
    "  - Index of a token is its unique ID\n",
    "- `VOCAB_TOKEN_TO_INDEX: dict[str, int]`\n",
    "  - Inverse mapping of `VOCAB_LIST`, maps tokens to unique IDs\n",
    "\n",
    "The following shows a visualization of the first 5 elements of each constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`VOCAB`: IsDataclass\n",
      "\tVOCAB.ADJLIST_START =\t'<ADJLIST_START>'\n",
      "\tVOCAB.ADJLIST_END =\t'<ADJLIST_END>'\n",
      "\tVOCAB.TARGET_START =\t'<TARGET_START>'\n",
      "\tVOCAB.TARGET_END =\t'<TARGET_END>'\n",
      "\tVOCAB.ORIGIN_START =\t'<ORIGIN_START>'\n",
      "\t...\n",
      "\n",
      "`VOCAB_LIST`: list[str]\n",
      "\t'<ADJLIST_START>'\n",
      "\t'<ADJLIST_END>'\n",
      "\t'<TARGET_START>'\n",
      "\t'<TARGET_END>'\n",
      "\t'<ORIGIN_START>'\n",
      "\t...\n",
      "\n",
      "`VOCAB_TOKEN_TO_INDEX`: dict[str, int]\n",
      "\t'<ADJLIST_START>':   \t0\n",
      "\t'<ADJLIST_END>':   \t1\n",
      "\t'<TARGET_START>':   \t2\n",
      "\t'<TARGET_END>':   \t3\n",
      "\t'<ORIGIN_START>':   \t4\n",
      "\t...\n"
     ]
    }
   ],
   "source": [
    "print(\"`VOCAB`: IsDataclass\")\n",
    "for i, t in enumerate(VOCAB):\n",
    "    if i >= 5: break\n",
    "    print(f\"\\tVOCAB.{t} =\\t'{getattr(VOCAB, t)}'\")\n",
    "print('\\t...')\n",
    "\n",
    "print(\"\\n`VOCAB_LIST`: list[str]\")\n",
    "for t in VOCAB_LIST[:5]:\n",
    "    print(f\"\\t'{t}'\")\n",
    "print('\\t...')\n",
    "    \n",
    "print(\"\\n`VOCAB_TOKEN_TO_INDEX`: dict[str, int]\")\n",
    "for t in VOCAB_TOKEN_TO_INDEX:\n",
    "    if VOCAB_TOKEN_TO_INDEX[t] >= 5: break\n",
    "    print(f\"\\t'{t}':   \\t{VOCAB_TOKEN_TO_INDEX[t]}\")\n",
    "print('\\t...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations of Static Vocabulary\n",
    "\n",
    "- No more rasterized vs uniform indexing, it's all fixed as uniform now\n",
    "- Fixed max grid size\n",
    "  - There is now a fixed maximum maze size which is supported.\n",
    "  - Unique tokens (`CoordTokenizers.UT`): 50x50\n",
    "  - Coordinate tuple tokens (`CoordTokenizers.CTT`): 128x128\n",
    "  - Mazes larger than these sizes are not supported\n",
    "  - There should be fewer compatibility issues with tokenizers using different `max_grid_size` parameters\n",
    "- Vocabulary access\n",
    "  - Since maze-dataset 1.0, there is no need to pass around a tokenizer object or any data structure to access its custom vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring your code from legacy `MazeTokenizer` and `TokenizationMode`\n",
    "Since `MazeTokenizerModular` uses a static vocabulary, it is not backwards compatible with any models trained using a legacy `MazeTokenizer`. The `maze-transformer` library is updated in vX.X.X to use `MazeTokenizerModular` by default. \n",
    "\n",
    "If you've manually specified a `MazeTokenizer` or `TokenizationMode` in your research code, the easiest way to refactor is using `MazeTokenizerModular.from_legacy`, which will convert a `MazeTokenizer` or `TokenizationMode` to its corresponding `MazeTokenizerModular` instance. Note that this correspondence means only that the stringification of mazes are equivalent; the encodings of strings to integer vocabulary indices are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MazeTokenizer(tokenization_mode=<TokenizationMode.AOTP_UT_uniform: 'AOTP_UT_uniform'>, max_grid_size=None) \n",
      " MazeTokenizerModular(prompt_sequencer=PromptSequencers.AOTP(coord_tokenizer=CoordTokenizers.UT(), adj_list_tokenizer=AdjListTokenizers.AdjListCoord(pre=False, post=True, shuffle_d0=True, edge_grouping=EdgeGroupings.Ungrouped(connection_token_ordinal=1), edge_subset=EdgeSubsets.ConnectionEdges(walls=False), edge_permuter=EdgePermuters.RandomCoords()), target_tokenizer=TargetTokenizers.Unlabeled(post=False), path_tokenizer=PathTokenizers.StepSequence(step_size=StepSizes.Singles(), step_tokenizers=(StepTokenizers.Coord(),), pre=False, intra=False, post=False)))\n"
     ]
    }
   ],
   "source": [
    "legacy_maze_tokenizer: MazeTokenizer = TokenizationMode.AOTP_UT_uniform.to_legacy_tokenizer()\n",
    "modular_tokenizer_equivalent: MazeTokenizerModular = MazeTokenizerModular.from_legacy(legacy_maze_tokenizer)\n",
    "print(legacy_maze_tokenizer, '\\n', modular_tokenizer_equivalent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_all_tokenizers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most combinations of `TokenizerElement`s and their arguments will produce a valid and unique `MazeTokenizerModular`. However, it is not guaranteed that every possible `MazeTokenizerModular` that can be constructed will make practical sense or have been put through testing.\n",
    "\n",
    "`get_all_tokenizers` constructs and caches all the tested tokenizers at once. For research investigating many different tokenization schemes, one practical way to access them is by looping through/sampling from `get_all_tokenizers()`. Be aware that the indexing of specific tokenizers may change without notice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: this cell fails because all_tokenizers is broken and takes too long. we kill it after a minute to give helpful error messages of where the long (infinite?) loop is.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# import threading\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# ALL_TOKENIZERS: list[MazeTokenizerModular] = get_all_tokenizers()\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mget_all_tokenizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshorten_numerical_to_str(\u001b[38;5;28mlen\u001b[39m(get_all_tokenizers()))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizers found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\tokenization\\all_tokenizers.py:59\u001b[0m, in \u001b[0;36mget_all_tokenizers\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;129m@cache\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_tokenizers\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[MazeTokenizerModular]:\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    Computes a complete list of all valid tokenizers.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    Warning: This is an expensive function.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_instances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mMazeTokenizerModular\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:412\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     fields: \u001b[38;5;28mlist\u001b[39m[field] \u001b[38;5;241m=\u001b[39m type_\u001b[38;5;241m.\u001b[39m__dataclass_fields__\n\u001b[0;32m    411\u001b[0m     fields_to_types: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m {f: fields[f]\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[1;32m--> 412\u001b[0m     all_arg_sequences: Iterable \u001b[38;5;241m=\u001b[39m \u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m            \u001b[49m\u001b[43mall_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields_to_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:424\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m    425\u001b[0m         (all_instances(sub, validation_funcs) \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m type_\u001b[38;5;241m.\u001b[39m__subclasses__()),\n\u001b[0;32m    426\u001b[0m         levels_to_flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    429\u001b[0m     get_origin(type_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    430\u001b[0m ):  \u001b[38;5;66;03m# Only matches Generic type tuple since regular tuple is not finite-valued\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;66;03m# Generic tuple: Similar to concrete dataclass. Construct all possible combinations of tuple fields.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(combo)\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m combo \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m         )\n\u001b[0;32m    440\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\misc.py:74\u001b[0m, in \u001b[0;36mflatten\u001b[1;34m(it, levels_to_flatten)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# TODO: swap type check with more general check for __iter__() or __next__() or whatever\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m levels_to_flatten \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m     ):\n\u001b[1;32m---> 74\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m     75\u001b[0m             x, \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m levels_to_flatten \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m         )\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\misc.py:67\u001b[0m, in \u001b[0;36mflatten\u001b[1;34m(it, levels_to_flatten)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(it: Iterable[Any], levels_to_flatten: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator:\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    Flattens an arbitrarily nested iterable.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    Flattens all iterable data types except for `str` and `bytes`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    - `levels_to_flatten`: Number of levels to flatten by, starting at the outermost layer. If `None`, performs full flattening.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;66;03m# TODO: swap type check with more general check for __iter__() or __next__() or whatever\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m levels_to_flatten \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m         ):\n\u001b[0;32m     74\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m     75\u001b[0m                 x, \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m levels_to_flatten \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m             )\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:418\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    411\u001b[0m     fields_to_types: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m {f: fields[f]\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[0;32m    412\u001b[0m     all_arg_sequences: Iterable \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m    414\u001b[0m             all_instances(arg_type, validation_funcs)\n\u001b[0;32m    415\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m arg_type \u001b[38;5;129;01min\u001b[39;00m fields_to_types\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    416\u001b[0m         ]\n\u001b[0;32m    417\u001b[0m     )\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m    425\u001b[0m         (all_instances(sub, validation_funcs) \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m type_\u001b[38;5;241m.\u001b[39m__subclasses__()),\n\u001b[0;32m    426\u001b[0m         levels_to_flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    427\u001b[0m     )\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:419\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    411\u001b[0m     fields_to_types: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m {f: fields[f]\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[0;32m    412\u001b[0m     all_arg_sequences: Iterable \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m    414\u001b[0m             all_instances(arg_type, validation_funcs)\n\u001b[0;32m    415\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m arg_type \u001b[38;5;129;01min\u001b[39;00m fields_to_types\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    416\u001b[0m         ]\n\u001b[0;32m    417\u001b[0m     )\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[1;32m--> 419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfields_to_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m    425\u001b[0m         (all_instances(sub, validation_funcs) \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m type_\u001b[38;5;241m.\u001b[39m__subclasses__()),\n\u001b[0;32m    426\u001b[0m         levels_to_flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    427\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: this cell fails because all_tokenizers is broken and takes too long. we kill it after a minute to give helpful error messages of where the long (infinite?) loop is.\n",
    "\n",
    "# import threading\n",
    "# import time\n",
    "# import signal\n",
    "\n",
    "# interrupt after a fixed time\n",
    "# def send_interrupt():\n",
    "# \ttime.sleep(60)\n",
    "# \tsignal.raise_signal(signal.SIGINT)\n",
    "\n",
    "# interrupt_thread = threading.Thread(target=send_interrupt)\n",
    "# interrupt_thread.start()\n",
    "# fancy_timeit_result = timeit_fancy(get_all_tokenizers, repeats=1, do_profiling=True, get_return=True, namespace=locals())\n",
    "\n",
    "# ALL_TOKENIZERS: list[MazeTokenizerModular] = get_all_tokenizers()\n",
    "print(f\"{len(get_all_tokenizers())} or {shorten_numerical_to_str(len(get_all_tokenizers()))} tokenizers found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other possible tokenizers which aren't in `get_all_tokenizers` are not guaranteed to function. Instead of running the expensive call to `get_all_tokenizers` yourself, you can check if a tokenizer is tested using `MazeTokenizerModular.is_tested_tokenizer` or `MazeTokenizerModular.is_valid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mt_default.is_tested_tokenizer()\n",
    "assert mt_default.is_valid()\n",
    "assert mt_ctt.is_tested_tokenizer()\n",
    "assert mt_ctt.is_valid()\n",
    "\n",
    "custom_untested_tokenizer = MazeTokenizerModular(\n",
    "    prompt_sequencer=PromptSequencers.AOP(\n",
    "        path_tokenizer=PathTokenizers.StepSequence(\n",
    "            step_tokenizers=(StepTokenizers.Distance(),) \n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "assert not custom_untested_tokenizer.is_tested_tokenizer()\n",
    "assert not custom_untested_tokenizer.is_valid()\n",
    "# Danger, use this tokenizer at your own risk!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Tokenizer Collections\n",
    "\n",
    "There are a several practical ways to filter down a collection of tokenizers, or alternatively, generate a new collection with a filter.\n",
    "\n",
    "**WARNING: Applying `filter` to the output of `get_all_tokenizers` is extremely slow due to the size of the initial population. Only use the first 3 methods for filtering much smaller collections of tokenizers. To generate a new collection based on filters, always use `utils.all_instances`**\n",
    "\n",
    "In order of increasing speed, power and decreasing syntactic concision:\n",
    "\n",
    "1. `MazeTokenizerModular.has_element`\n",
    "    - Use case: Use with `filter` for concise, basic filtering on an existing collection\n",
    "1. `MazeTokenizerModular.tokenizer_elements`\n",
    "    - Use case: Use with `filter` for more precise filtering on an existing collection\n",
    "1. `MazeTokenizerModular.summary`\n",
    "    - Use case: Use with `filter` for more precise filtering on an existing collection\n",
    "1. `utils.all_instances`\n",
    "    - Use case: Generate a new collection with filter(s).\n",
    "    - Anytime you don't already have a small collection of tokenizers as the starting population.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_all = len(get_all_tokenizers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m filtered_1: \u001b[38;5;28mlist\u001b[39m[MazeTokenizerModular] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_instances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMazeTokenizerModular\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mMAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Always include this as the first item in the dict whenever calling `all_instances` with `MazeTokenizerModular` or any `TokenizerElement`\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# CoordTokenizers._CoordTokenizer: lambda x: isinstance(x, CoordTokenizers.UT),\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mStepTokenizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStepTokenizerPermutation\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mStepTokenizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCardinal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# AdjListTokenizers._AdjListTokenizer: lambda x: isinstance(x, AdjListTokenizers.AdjListCardinal),\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mEdgeSubsets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_EdgeSubset\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEdgeSubsets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConnectionEdges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m filtered_2: \u001b[38;5;28mlist\u001b[39m[MazeTokenizerModular] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m     14\u001b[0m     all_instances(\n\u001b[0;32m     15\u001b[0m         MazeTokenizerModular,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     )\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m filtered_3: \u001b[38;5;28mlist\u001b[39m[MazeTokenizerModular] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m     23\u001b[0m     all_instances(\n\u001b[0;32m     24\u001b[0m         MazeTokenizerModular,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     33\u001b[0m )\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:412\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     fields: \u001b[38;5;28mlist\u001b[39m[field] \u001b[38;5;241m=\u001b[39m type_\u001b[38;5;241m.\u001b[39m__dataclass_fields__\n\u001b[0;32m    411\u001b[0m     fields_to_types: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m {f: fields[f]\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[1;32m--> 412\u001b[0m     all_arg_sequences: Iterable \u001b[38;5;241m=\u001b[39m \u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m            \u001b[49m\u001b[43mall_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields_to_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:424\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m    425\u001b[0m         (all_instances(sub, validation_funcs) \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m type_\u001b[38;5;241m.\u001b[39m__subclasses__()),\n\u001b[0;32m    426\u001b[0m         levels_to_flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    429\u001b[0m     get_origin(type_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    430\u001b[0m ):  \u001b[38;5;66;03m# Only matches Generic type tuple since regular tuple is not finite-valued\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;66;03m# Generic tuple: Similar to concrete dataclass. Construct all possible combinations of tuple fields.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(combo)\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m combo \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m         )\n\u001b[0;32m    440\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\misc.py:74\u001b[0m, in \u001b[0;36mflatten\u001b[1;34m(it, levels_to_flatten)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# TODO: swap type check with more general check for __iter__() or __next__() or whatever\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m levels_to_flatten \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m     ):\n\u001b[1;32m---> 74\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m     75\u001b[0m             x, \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m levels_to_flatten \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m         )\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\misc.py:67\u001b[0m, in \u001b[0;36mflatten\u001b[1;34m(it, levels_to_flatten)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(it: Iterable[Any], levels_to_flatten: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator:\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    Flattens an arbitrarily nested iterable.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    Flattens all iterable data types except for `str` and `bytes`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    - `levels_to_flatten`: Number of levels to flatten by, starting at the outermost layer. If `None`, performs full flattening.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;66;03m# TODO: swap type check with more general check for __iter__() or __next__() or whatever\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m levels_to_flatten \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m         ):\n\u001b[0;32m     74\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m     75\u001b[0m                 x, \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m levels_to_flatten \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m             )\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:412\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     fields: \u001b[38;5;28mlist\u001b[39m[field] \u001b[38;5;241m=\u001b[39m type_\u001b[38;5;241m.\u001b[39m__dataclass_fields__\n\u001b[0;32m    411\u001b[0m     fields_to_types: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m {f: fields[f]\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[1;32m--> 412\u001b[0m     all_arg_sequences: Iterable \u001b[38;5;241m=\u001b[39m \u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m            \u001b[49m\u001b[43mall_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields_to_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:424\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m    425\u001b[0m         (all_instances(sub, validation_funcs) \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m type_\u001b[38;5;241m.\u001b[39m__subclasses__()),\n\u001b[0;32m    426\u001b[0m         levels_to_flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    429\u001b[0m     get_origin(type_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    430\u001b[0m ):  \u001b[38;5;66;03m# Only matches Generic type tuple since regular tuple is not finite-valued\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;66;03m# Generic tuple: Similar to concrete dataclass. Construct all possible combinations of tuple fields.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(combo)\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m combo \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m         )\n\u001b[0;32m    440\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\misc.py:74\u001b[0m, in \u001b[0;36mflatten\u001b[1;34m(it, levels_to_flatten)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# TODO: swap type check with more general check for __iter__() or __next__() or whatever\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m levels_to_flatten \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m     ):\n\u001b[1;32m---> 74\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m     75\u001b[0m             x, \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m levels_to_flatten \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m         )\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\misc.py:67\u001b[0m, in \u001b[0;36mflatten\u001b[1;34m(it, levels_to_flatten)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(it: Iterable[Any], levels_to_flatten: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator:\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    Flattens an arbitrarily nested iterable.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    Flattens all iterable data types except for `str` and `bytes`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    - `levels_to_flatten`: Number of levels to flatten by, starting at the outermost layer. If `None`, performs full flattening.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;66;03m# TODO: swap type check with more general check for __iter__() or __next__() or whatever\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m levels_to_flatten \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m         ):\n\u001b[0;32m     74\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m     75\u001b[0m                 x, \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m levels_to_flatten \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m             )\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:412\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     fields: \u001b[38;5;28mlist\u001b[39m[field] \u001b[38;5;241m=\u001b[39m type_\u001b[38;5;241m.\u001b[39m__dataclass_fields__\n\u001b[0;32m    411\u001b[0m     fields_to_types: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m {f: fields[f]\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[1;32m--> 412\u001b[0m     all_arg_sequences: Iterable \u001b[38;5;241m=\u001b[39m \u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m            \u001b[49m\u001b[43mall_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields_to_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m filtered_1: \u001b[38;5;28mlist\u001b[39m[MazeTokenizerModular] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m      2\u001b[0m     all_instances(\n\u001b[0;32m      3\u001b[0m         MazeTokenizerModular,\n\u001b[0;32m      4\u001b[0m         {\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mMAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS, \u001b[38;5;66;03m# Always include this as the first item in the dict whenever calling `all_instances` with `MazeTokenizerModular` or any `TokenizerElement`\u001b[39;00m\n\u001b[0;32m      6\u001b[0m             \u001b[38;5;66;03m# CoordTokenizers._CoordTokenizer: lambda x: isinstance(x, CoordTokenizers.UT),\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m             StepTokenizers\u001b[38;5;241m.\u001b[39mStepTokenizerPermutation: \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mStepTokenizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCardinal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      8\u001b[0m             \u001b[38;5;66;03m# AdjListTokenizers._AdjListTokenizer: lambda x: isinstance(x, AdjListTokenizers.AdjListCardinal),\u001b[39;00m\n\u001b[0;32m      9\u001b[0m             EdgeSubsets\u001b[38;5;241m.\u001b[39m_EdgeSubset: \u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m==\u001b[39m EdgeSubsets\u001b[38;5;241m.\u001b[39mConnectionEdges(walls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     10\u001b[0m         }\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m filtered_2: \u001b[38;5;28mlist\u001b[39m[MazeTokenizerModular] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m     14\u001b[0m     all_instances(\n\u001b[0;32m     15\u001b[0m         MazeTokenizerModular,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     )\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m filtered_3: \u001b[38;5;28mlist\u001b[39m[MazeTokenizerModular] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m     23\u001b[0m     all_instances(\n\u001b[0;32m     24\u001b[0m         MazeTokenizerModular,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     33\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\serializable_dataclass.py:657\u001b[0m, in \u001b[0;36mserializable_dataclass.<locals>.wrap.<locals>.<lambda>\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_fields_types \u001b[38;5;241m=\u001b[39m SerializableDataclass__validate_fields_types  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# type is `Callable[[T, T], bool]`\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__eq__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, other: \u001b[43mdc_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;66;03m# Register the class with ZANJ\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m register_handler:\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:252\u001b[0m, in \u001b[0;36mdc_eq\u001b[1;34m(dc1, dc2, except_when_class_mismatch, false_when_class_mismatch, except_when_field_mismatch)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdc1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:253\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m--> 253\u001b[0m     \u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fld \u001b[38;5;129;01min\u001b[39;00m dataclasses\u001b[38;5;241m.\u001b[39mfields(dc1)\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fld\u001b[38;5;241m.\u001b[39mcompare\n\u001b[0;32m    256\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36marray_safe_eq\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a1, b1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, b))\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36marray_safe_eq\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a1, b1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, b))\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "    \u001b[1;31m[... skipping similar frames: <genexpr> at line 152 (979 times), array_safe_eq at line 152 (979 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36marray_safe_eq\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a1, b1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, b))\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:151\u001b[0m, in \u001b[0;36marray_safe_eq\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(a)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas.core.frame.DataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(b)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas.core.frame.DataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m ):\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequence\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array_safe_eq(a1, b1) \u001b[38;5;28;01mfor\u001b[39;00m a1, b1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, b))\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\typing.py:994\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__instancecheck__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__subclasscheck__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\typing.py:1158\u001b[0m, in \u001b[0;36m_SpecialGenericAlias.__subclasscheck__\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__)\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, _GenericAlias):\n\u001b[1;32m-> 1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__origin__\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[1;34m(cls, subclass)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, subclass):\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_subclasscheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "filtered_1: list[MazeTokenizerModular] = list(\n",
    "    all_instances(\n",
    "        MazeTokenizerModular,\n",
    "        {\n",
    "            **MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS, # Always include this as the first item in the dict whenever calling `all_instances` with `MazeTokenizerModular` or any `_TokenizerElement`\n",
    "            CoordTokenizers._CoordTokenizer: lambda x: isinstance(x, CoordTokenizers.UT),\n",
    "            StepTokenizers.StepTokenizerPermutation: lambda x: x[0] == StepTokenizers.Cardinal() and len(x) < 3,\n",
    "            AdjListTokenizers._AdjListTokenizer: lambda x: isinstance(x, AdjListTokenizers.AdjListCardinal),\n",
    "            EdgeSubsets._EdgeSubset: lambda x: x == EdgeSubsets.ConnectionEdges(walls=False),\n",
    "        }\n",
    "    )\n",
    ")\n",
    "filtered_2: list[MazeTokenizerModular] = list(\n",
    "    all_instances(\n",
    "        MazeTokenizerModular,\n",
    "        {\n",
    "            **MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS, # Always include this as the first item in the dict whenever calling`all_instances` with `MazeTokenizerModular` or any `_TokenizerElement`\n",
    "            _TokenizerElement: lambda x: x.is_valid() and not getattr(x, \"pre\", False) and not getattr(x, \"intra\", False) and not getattr(x, \"post\", False),  # Minimal delimiters everywhere...\n",
    "            CoordTokenizers.CTT: lambda x: x.pre and x.intra and x.post,  # ...except for the coord tokens\n",
    "        }\n",
    "    )\n",
    ")\n",
    "filtered_3: list[MazeTokenizerModular] = list(\n",
    "    all_instances(\n",
    "        MazeTokenizerModular,\n",
    "        {\n",
    "            **MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS, # Always include this as the first item in the dict whenever calling `all_instances` with `MazeTokenizerModular` or any `_TokenizerElement`\n",
    "            PromptSequencers._PromptSequencer: lambda x: isinstance(x, PromptSequencers.AOTP),\n",
    "            TargetTokenizers._TargetTokenizer: lambda x: x == TargetTokenizers.Unlabeled(),\n",
    "            StepSizes.Singles: lambda x: False,\n",
    "\n",
    "        }\n",
    "    )\n",
    ")\n",
    "print(f\"filtered 1: {len(filtered_1)} tokenizers / {len_all} tokenizers\")\n",
    "print(f\"filtered 2: {len(filtered_2)} tokenizers / {len_all} tokenizers\")\n",
    "print(f\"filtered 3: {len(filtered_3)} tokenizers / {len_all} tokenizers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples below show equivalent methods of filtering one of the smaller collections above using options 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_has_element: list[MazeTokenizerModular] = list(filter(\n",
    "    lambda x: x.has_element(EdgePermuters.BothCoords())\n",
    ", filtered_1))\n",
    "\n",
    "filtered_tokenizer_elements: list[MazeTokenizerModular] = list(filter(\n",
    "    lambda x: EdgePermuters.BothCoords() in x.tokenizer_elements\n",
    ", filtered_1))\n",
    "\n",
    "filtered_summary: list[MazeTokenizerModular] = list(filter(\n",
    "    lambda x: x.summary()[\"edge_permuter\"] == EdgePermuters.BothCoords()\n",
    ", filtered_1))\n",
    "\n",
    "print(f\"filtered: {len(filtered_has_element)} tokenizers / {len_all} tokenizers\")\n",
    "\n",
    "assert set(filtered_has_element) == set(filtered_tokenizer_elements)\n",
    "assert set(filtered_has_element) == set(filtered_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TokenizerElement Behavior Reference\n",
    "\n",
    "For each primary `TokenizerElement`, tokenizations and encodings derived from the below maze are logged in DataFrames for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to get the dataset 'test-g3-n1-a_dfs-h50097'\n",
      "generating dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating & solving mazes: 100%|| 1/1 [00:00<00:00, 283.51maze/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got dataset test with 1 items. output.cfg.to_fname() = 'test-g3-n1-a_dfs-h50097'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cfg: MazeDatasetConfig = MazeDatasetConfig(\n",
    "    name=\"test\",\n",
    "    grid_n=3,\n",
    "    n_mazes=1,\n",
    "    maze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    ")\n",
    "dataset: MazeDataset = MazeDataset.from_config(\n",
    "    cfg,\n",
    "    do_download=False,\n",
    "    load_local=False,\n",
    "    do_generate=True,\n",
    "    save_local=False,\n",
    "    verbose=True,\n",
    "    gen_parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "mz: SolvedMaze = dataset[0]\n",
    "MazePlot(mz).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_elements_df(\n",
    "        elem_type: type[_TokenizerElement], \n",
    "        encoding=True, \n",
    "        **to_tokens_kwargs\n",
    "        ) -> pd.DataFrame:\n",
    "    columns = [\"_TokenizerElement\", \"tokens\"]\n",
    "    if encoding:\n",
    "        columns.append(\"encoding\")\n",
    "    tokenizers: pd.DataFrame = pd.DataFrame(columns=columns)\n",
    "\n",
    "    tokenizers[\"_TokenizerElement\"] = list(all_instances(elem_type, validation_funcs=MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS))\n",
    "    tokenizers[\"tokens\"] = tokenizers[\"_TokenizerElement\"].apply(lambda x: \" \".join(x.to_tokens(**to_tokens_kwargs)))\n",
    "    if encoding:\n",
    "        tokenizers[\"encoding\"] = tokenizers[\"tokens\"].apply(lambda x: MazeTokenizerModular.encode(x))\n",
    "    return tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CoordTokenizers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TokenizerElement</th>\n",
       "      <th>tokens</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UT()</td>\n",
       "      <td>(1,2)</td>\n",
       "      <td>[1602]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTT(pre=T, intra=T, post=T)</td>\n",
       "      <td>( 1 , 2 )</td>\n",
       "      <td>[11, 321, 12, 322, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CTT(pre=T, intra=T, post=F)</td>\n",
       "      <td>( 1 , 2</td>\n",
       "      <td>[11, 321, 12, 322]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTT(pre=T, intra=F, post=T)</td>\n",
       "      <td>( 1 2 )</td>\n",
       "      <td>[11, 321, 322, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTT(pre=T, intra=F, post=F)</td>\n",
       "      <td>( 1 2</td>\n",
       "      <td>[11, 321, 322]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CTT(pre=F, intra=T, post=T)</td>\n",
       "      <td>1 , 2 )</td>\n",
       "      <td>[321, 12, 322, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTT(pre=F, intra=T, post=F)</td>\n",
       "      <td>1 , 2</td>\n",
       "      <td>[321, 12, 322]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CTT(pre=F, intra=F, post=T)</td>\n",
       "      <td>1 2 )</td>\n",
       "      <td>[321, 322, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CTT(pre=F, intra=F, post=F)</td>\n",
       "      <td>1 2</td>\n",
       "      <td>[321, 322]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TokenizerElement     tokens                encoding\n",
       "0                         UT()      (1,2)                  [1602]\n",
       "1  CTT(pre=T, intra=T, post=T)  ( 1 , 2 )  [11, 321, 12, 322, 13]\n",
       "2  CTT(pre=T, intra=T, post=F)    ( 1 , 2      [11, 321, 12, 322]\n",
       "3  CTT(pre=T, intra=F, post=T)    ( 1 2 )      [11, 321, 322, 13]\n",
       "4  CTT(pre=T, intra=F, post=F)      ( 1 2          [11, 321, 322]\n",
       "5  CTT(pre=F, intra=T, post=T)    1 , 2 )      [321, 12, 322, 13]\n",
       "6  CTT(pre=F, intra=T, post=F)      1 , 2          [321, 12, 322]\n",
       "7  CTT(pre=F, intra=F, post=T)      1 2 )          [321, 322, 13]\n",
       "8  CTT(pre=F, intra=F, post=F)        1 2              [321, 322]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_tokenizers = all_elements_df(CoordTokenizers._CoordTokenizer, coord=mz.solution[0])\n",
    "coord_tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency List Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TokenizerElement</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), AllLatticeEdges(), SortedCoords())</td>\n",
       "      <td>&lt;XX&gt; (0,0) (0,1) ; &lt;--&gt; (0,0) (1,0) ; &lt;XX&gt; (0,1) (0,2) ; &lt;--&gt; (0,1) (1,1) ; &lt;--&gt; (0,2) (1,2) ; &lt;XX&gt; (1,0) (1,1) ; &lt;--&gt; (1,0) (2,0) ; &lt;--&gt; (1,1) (1,2) ; &lt;XX&gt; (1,1) (2,1) ; &lt;--&gt; (1,2) (2,2) ; &lt;--&gt; (2,0) (2,1) ; &lt;--&gt; (2,1) (2,2) ;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), AllLatticeEdges(), RandomCoords())</td>\n",
       "      <td>&lt;XX&gt; (0,1) (0,0) ; &lt;XX&gt; (0,2) (0,1) ; &lt;XX&gt; (1,1) (1,0) ; &lt;--&gt; (1,2) (1,1) ; &lt;--&gt; (2,1) (2,0) ; &lt;--&gt; (2,2) (2,1) ; &lt;--&gt; (1,0) (0,0) ; &lt;--&gt; (1,1) (0,1) ; &lt;--&gt; (1,2) (0,2) ; &lt;--&gt; (2,0) (1,0) ; &lt;XX&gt; (2,1) (1,1) ; &lt;--&gt; (2,2) (1,2) ;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), AllLatticeEdges(), BothCoords())</td>\n",
       "      <td>&lt;XX&gt; (0,0) (0,1) ; &lt;XX&gt; (0,1) (0,2) ; &lt;XX&gt; (1,0) (1,1) ; &lt;--&gt; (1,1) (1,2) ; &lt;--&gt; (2,0) (2,1) ; &lt;--&gt; (2,1) (2,2) ; &lt;--&gt; (0,0) (1,0) ; &lt;--&gt; (0,1) (1,1) ; &lt;--&gt; (0,2) (1,2) ; &lt;--&gt; (1,0) (2,0) ; &lt;XX&gt; (1,1) (2,1) ; &lt;--&gt; (1,2) (2,2) ; &lt;XX&gt; (0,1) (0,0) ; &lt;XX&gt; (0,2) (0,1) ; &lt;XX&gt; (1,1) (1,0) ; &lt;--&gt; (1,2) (1,1) ; &lt;--&gt; (2,1) (2,0) ; &lt;--&gt; (2,2) (2,1) ; &lt;--&gt; (1,0) (0,0) ; &lt;--&gt; (1,1) (0,1) ; &lt;--&gt; (1,2) (0,2) ; &lt;--&gt; (2,0) (1,0) ; &lt;XX&gt; (2,1) (1,1) ; &lt;--&gt; (2,2) (1,2) ;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), ConnectionEdges(walls=T), SortedCoords())</td>\n",
       "      <td>&lt;XX&gt; (0,0) (0,1) ; &lt;XX&gt; (0,1) (0,2) ; &lt;XX&gt; (1,0) (1,1) ; &lt;XX&gt; (1,1) (2,1) ;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), ConnectionEdges(walls=T), RandomCoords())</td>\n",
       "      <td>&lt;XX&gt; (1,1) (2,1) ; &lt;XX&gt; (0,0) (0,1) ; &lt;XX&gt; (0,1) (0,2) ; &lt;XX&gt; (1,0) (1,1) ;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=T), RandomCoords())</td>\n",
       "      <td>(2,1) NORTH &lt;XX&gt; (0,1) WEST &lt;XX&gt; (0,2) WEST &lt;XX&gt; (1,1) WEST &lt;XX&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=T), BothCoords())</td>\n",
       "      <td>(1,1) SOUTH &lt;XX&gt; (0,0) EAST &lt;XX&gt; (0,1) EAST &lt;XX&gt; (1,0) EAST &lt;XX&gt; (2,1) NORTH &lt;XX&gt; (0,1) WEST &lt;XX&gt; (0,2) WEST &lt;XX&gt; (1,1) WEST &lt;XX&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=F), SortedCoords())</td>\n",
       "      <td>(0,0) SOUTH &lt;--&gt; (0,1) SOUTH &lt;--&gt; (0,2) SOUTH &lt;--&gt; (1,0) SOUTH &lt;--&gt; (1,1) EAST &lt;--&gt; (1,2) SOUTH &lt;--&gt; (2,0) EAST &lt;--&gt; (2,1) EAST &lt;--&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=F), RandomCoords())</td>\n",
       "      <td>(1,0) NORTH &lt;--&gt; (1,1) NORTH &lt;--&gt; (1,2) NORTH &lt;--&gt; (2,0) NORTH &lt;--&gt; (2,2) NORTH &lt;--&gt; (1,2) WEST &lt;--&gt; (2,1) WEST &lt;--&gt; (2,2) WEST &lt;--&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=F), BothCoords())</td>\n",
       "      <td>(0,0) SOUTH &lt;--&gt; (0,1) SOUTH &lt;--&gt; (0,2) SOUTH &lt;--&gt; (1,0) SOUTH &lt;--&gt; (1,2) SOUTH &lt;--&gt; (1,1) EAST &lt;--&gt; (2,0) EAST &lt;--&gt; (2,1) EAST &lt;--&gt; (1,0) NORTH &lt;--&gt; (1,1) NORTH &lt;--&gt; (1,2) NORTH &lt;--&gt; (2,0) NORTH &lt;--&gt; (2,2) NORTH &lt;--&gt; (1,2) WEST &lt;--&gt; (2,1) WEST &lt;--&gt; (2,2) WEST &lt;--&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  TokenizerElement  \\\n",
       "0              AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), AllLatticeEdges(), SortedCoords())   \n",
       "1              AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), AllLatticeEdges(), RandomCoords())   \n",
       "2                AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), AllLatticeEdges(), BothCoords())   \n",
       "3       AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), ConnectionEdges(walls=T), SortedCoords())   \n",
       "4       AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=0), ConnectionEdges(walls=T), RandomCoords())   \n",
       "..                                                                                                                             ...   \n",
       "211  AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=T), RandomCoords())   \n",
       "212    AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=T), BothCoords())   \n",
       "213  AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=F), SortedCoords())   \n",
       "214  AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=F), RandomCoords())   \n",
       "215    AdjListCardinal(pre=F, post=F, shuffle_d0=F, Ungrouped(connection_token_ordinal=2), ConnectionEdges(walls=F), BothCoords())   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tokens  \n",
       "0                                                                                                                                                                                                                                        <XX> (0,0) (0,1) ; <--> (0,0) (1,0) ; <XX> (0,1) (0,2) ; <--> (0,1) (1,1) ; <--> (0,2) (1,2) ; <XX> (1,0) (1,1) ; <--> (1,0) (2,0) ; <--> (1,1) (1,2) ; <XX> (1,1) (2,1) ; <--> (1,2) (2,2) ; <--> (2,0) (2,1) ; <--> (2,1) (2,2) ;  \n",
       "1                                                                                                                                                                                                                                        <XX> (0,1) (0,0) ; <XX> (0,2) (0,1) ; <XX> (1,1) (1,0) ; <--> (1,2) (1,1) ; <--> (2,1) (2,0) ; <--> (2,2) (2,1) ; <--> (1,0) (0,0) ; <--> (1,1) (0,1) ; <--> (1,2) (0,2) ; <--> (2,0) (1,0) ; <XX> (2,1) (1,1) ; <--> (2,2) (1,2) ;  \n",
       "2    <XX> (0,0) (0,1) ; <XX> (0,1) (0,2) ; <XX> (1,0) (1,1) ; <--> (1,1) (1,2) ; <--> (2,0) (2,1) ; <--> (2,1) (2,2) ; <--> (0,0) (1,0) ; <--> (0,1) (1,1) ; <--> (0,2) (1,2) ; <--> (1,0) (2,0) ; <XX> (1,1) (2,1) ; <--> (1,2) (2,2) ; <XX> (0,1) (0,0) ; <XX> (0,2) (0,1) ; <XX> (1,1) (1,0) ; <--> (1,2) (1,1) ; <--> (2,1) (2,0) ; <--> (2,2) (2,1) ; <--> (1,0) (0,0) ; <--> (1,1) (0,1) ; <--> (1,2) (0,2) ; <--> (2,0) (1,0) ; <XX> (2,1) (1,1) ; <--> (2,2) (1,2) ;  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                <XX> (0,0) (0,1) ; <XX> (0,1) (0,2) ; <XX> (1,0) (1,1) ; <XX> (1,1) (2,1) ;  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                <XX> (1,1) (2,1) ; <XX> (0,0) (0,1) ; <XX> (0,1) (0,2) ; <XX> (1,0) (1,1) ;  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...  \n",
       "211                                                                                                                                                                                                                                                                                                                                                                                                         (2,1) NORTH <XX> (0,1) WEST <XX> (0,2) WEST <XX> (1,1) WEST <XX>  \n",
       "212                                                                                                                                                                                                                                                                                                                                        (1,1) SOUTH <XX> (0,0) EAST <XX> (0,1) EAST <XX> (1,0) EAST <XX> (2,1) NORTH <XX> (0,1) WEST <XX> (0,2) WEST <XX> (1,1) WEST <XX>  \n",
       "213                                                                                                                                                                                                                                                                                                                                     (0,0) SOUTH <--> (0,1) SOUTH <--> (0,2) SOUTH <--> (1,0) SOUTH <--> (1,1) EAST <--> (1,2) SOUTH <--> (2,0) EAST <--> (2,1) EAST <-->  \n",
       "214                                                                                                                                                                                                                                                                                                                                     (1,0) NORTH <--> (1,1) NORTH <--> (1,2) NORTH <--> (2,0) NORTH <--> (2,2) NORTH <--> (1,2) WEST <--> (2,1) WEST <--> (2,2) WEST <-->  \n",
       "215                                                                                                                                                                                                (0,0) SOUTH <--> (0,1) SOUTH <--> (0,2) SOUTH <--> (1,0) SOUTH <--> (1,2) SOUTH <--> (1,1) EAST <--> (2,0) EAST <--> (2,1) EAST <--> (1,0) NORTH <--> (1,1) NORTH <--> (1,2) NORTH <--> (2,0) NORTH <--> (2,2) NORTH <--> (1,2) WEST <--> (2,1) WEST <--> (2,2) WEST <-->  \n",
       "\n",
       "[216 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjlist_tokenizers = all_elements_df(AdjListTokenizers._AdjListTokenizer, encoding=False, maze=mz, coord_tokenizer=CoordTokenizers.UT())\n",
    "adjlist_tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TokenizerElement</th>\n",
       "      <th>tokens</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unlabeled(post=T)</td>\n",
       "      <td>(0,0) ||</td>\n",
       "      <td>[1596, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unlabeled(post=F)</td>\n",
       "      <td>(0,0)</td>\n",
       "      <td>[1596]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TokenizerElement    tokens    encoding\n",
       "0  Unlabeled(post=T)  (0,0) ||  [1596, 15]\n",
       "1  Unlabeled(post=F)     (0,0)      [1596]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tokenizers = all_elements_df(TargetTokenizers._TargetTokenizer, targets=[mz.end_pos], coord_tokenizer=CoordTokenizers.UT())\n",
    "target_tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded in comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m path_tokenizers \u001b[38;5;241m=\u001b[39m \u001b[43mall_elements_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPathTokenizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_PathTokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoord_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCoordTokenizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUT\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m path_tokenizers\n",
      "Cell \u001b[1;32mIn[30], line 11\u001b[0m, in \u001b[0;36mall_elements_df\u001b[1;34m(elem_type, encoding, **to_tokens_kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m     columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m tokenizers: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[1;32m---> 11\u001b[0m tokenizers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizerElement\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m tokenizers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizerElement\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x\u001b[38;5;241m.\u001b[39mto_tokens(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_tokens_kwargs)))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding:\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:424\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m    425\u001b[0m         (all_instances(sub, validation_funcs) \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m type_\u001b[38;5;241m.\u001b[39m__subclasses__()),\n\u001b[0;32m    426\u001b[0m         levels_to_flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    429\u001b[0m     get_origin(type_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    430\u001b[0m ):  \u001b[38;5;66;03m# Only matches Generic type tuple since regular tuple is not finite-valued\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;66;03m# Generic tuple: Similar to concrete dataclass. Construct all possible combinations of tuple fields.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(combo)\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m combo \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m         )\n\u001b[0;32m    440\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\misc.py:74\u001b[0m, in \u001b[0;36mflatten\u001b[1;34m(it, levels_to_flatten)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# TODO: swap type check with more general check for __iter__() or __next__() or whatever\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m levels_to_flatten \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m     ):\n\u001b[1;32m---> 74\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m     75\u001b[0m             x, \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m levels_to_flatten \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m         )\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\misc.py:67\u001b[0m, in \u001b[0;36mflatten\u001b[1;34m(it, levels_to_flatten)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(it: Iterable[Any], levels_to_flatten: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator:\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    Flattens an arbitrarily nested iterable.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    Flattens all iterable data types except for `str` and `bytes`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    - `levels_to_flatten`: Number of levels to flatten by, starting at the outermost layer. If `None`, performs full flattening.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;66;03m# TODO: swap type check with more general check for __iter__() or __next__() or whatever\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m levels_to_flatten \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m         ):\n\u001b[0;32m     74\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m flatten(\n\u001b[0;32m     75\u001b[0m                 x, \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m levels_to_flatten \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m levels_to_flatten \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m             )\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\utils.py:412\u001b[0m, in \u001b[0;36mall_instances\u001b[1;34m(type_, validation_funcs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     fields: \u001b[38;5;28mlist\u001b[39m[field] \u001b[38;5;241m=\u001b[39m type_\u001b[38;5;241m.\u001b[39m__dataclass_fields__\n\u001b[0;32m    411\u001b[0m     fields_to_types: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m {f: fields[f]\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[1;32m--> 412\u001b[0m     all_arg_sequences: Iterable \u001b[38;5;241m=\u001b[39m \u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m            \u001b[49m\u001b[43mall_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields_to_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\n\u001b[0;32m    419\u001b[0m         type_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{fld: arg \u001b[38;5;28;01mfor\u001b[39;00m fld, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fields_to_types\u001b[38;5;241m.\u001b[39mkeys(), args)})\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m all_arg_sequences\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataclass_fields__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_abstract(type_):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# Abstract dataclass: call `all_instances` on each subclass\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\NTFS\\dev\\Unsearch\\maze-dataset\\maze_dataset\\tokenization\\all_tokenizers.py:50\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmaze_dataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m all_instances, FiniteValued\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Always include this as the first item in the dict `validation_funcs` whenever using `all_instances` with `MazeTokenizerModular`\u001b[39;00m\n\u001b[0;32m     44\u001b[0m MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS: frozendict\u001b[38;5;241m.\u001b[39mfrozendict[\u001b[38;5;28mtype\u001b[39m, Callable[[FiniteValued], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m frozendict\u001b[38;5;241m.\u001b[39mfrozendict({\n\u001b[0;32m     45\u001b[0m     TokenizerElement: \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mis_valid(),\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Currently no need for `MazeTokenizerModular.is_valid` since that method contains no special cases not already covered by `TokenizerElement.is_valid`\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# MazeTokenizerModular: lambda x: x.is_valid(),\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     StepTokenizers\u001b[38;5;241m.\u001b[39mStepTokenizerPermutation: \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(x))\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mStepTokenizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     51\u001b[0m })\n\u001b[0;32m     53\u001b[0m \u001b[38;5;129m@cache\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_tokenizers\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[MazeTokenizerModular]:\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    Computes a complete list of all valid tokenizers.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    Warning: This is an expensive function.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\serializable_dataclass.py:657\u001b[0m, in \u001b[0;36mserializable_dataclass.<locals>.wrap.<locals>.<lambda>\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_fields_types \u001b[38;5;241m=\u001b[39m SerializableDataclass__validate_fields_types  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# type is `Callable[[T, T], bool]`\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__eq__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, other: \u001b[43mdc_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;66;03m# Register the class with ZANJ\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m register_handler:\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:252\u001b[0m, in \u001b[0;36mdc_eq\u001b[1;34m(dc1, dc2, except_when_class_mismatch, false_when_class_mismatch, except_when_field_mismatch)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdc1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:253\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m--> 253\u001b[0m     \u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fld \u001b[38;5;129;01min\u001b[39;00m dataclasses\u001b[38;5;241m.\u001b[39mfields(dc1)\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fld\u001b[38;5;241m.\u001b[39mcompare\n\u001b[0;32m    256\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36marray_safe_eq\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a1, b1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, b))\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36marray_safe_eq\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a1, b1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, b))\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "    \u001b[1;31m[... skipping similar frames: <genexpr> at line 152 (980 times), array_safe_eq at line 152 (980 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36marray_safe_eq\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:152\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, typing\u001b[38;5;241m.\u001b[39mSequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43marray_safe_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a1, b1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, b))\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    156\u001b[0m         array_safe_eq(k1, k2) \u001b[38;5;129;01mand\u001b[39;00m array_safe_eq(a[k1], b[k2])\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a\u001b[38;5;241m.\u001b[39mkeys(), b\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    158\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaron\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-dataset-h6YQ-YyV-py3.10\\lib\\site-packages\\muutils\\json_serialize\\util.py:151\u001b[0m, in \u001b[0;36marray_safe_eq\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(a)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas.core.frame.DataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(b)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas.core.frame.DataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m ):\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mequals(b)\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequence\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, typing\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array_safe_eq(a1, b1) \u001b[38;5;28;01mfor\u001b[39;00m a1, b1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, b))\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mdict\u001b[39m, typing\u001b[38;5;241m.\u001b[39mMapping)):\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\typing.py:994\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__instancecheck__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__subclasscheck__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\typing.py:1158\u001b[0m, in \u001b[0;36m_SpecialGenericAlias.__subclasscheck__\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__)\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, _GenericAlias):\n\u001b[1;32m-> 1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__origin__\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[1;34m(cls, subclass)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, subclass):\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_subclasscheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded in comparison"
     ]
    }
   ],
   "source": [
    "path_tokenizers = all_elements_df(PathTokenizers._PathTokenizer, maze=mz, coord_tokenizer=CoordTokenizers.UT())\n",
    "path_tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Sequencers\n",
    "\n",
    "Currently, the only difference in possible prompt sequencers is the inclusion/exclusion of target tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TokenizerElement</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AOTP(UT(), AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=1), ConnectionEdges(walls=F), RandomCoords()), Unlabeled(post=F), StepSequence(Singles(), step_tokenizers=(Coord(), ), pre=F, intra=F, post=F))</td>\n",
       "      <td>&lt;ADJLIST_START&gt; (1,0) &lt;--&gt; (0,0) ; (1,1) &lt;--&gt; (0,1) ; (1,2) &lt;--&gt; (0,2) ; (2,0) &lt;--&gt; (1,0) ; (2,2) &lt;--&gt; (1,2) ; (1,2) &lt;--&gt; (1,1) ; (2,1) &lt;--&gt; (2,0) ; (2,2) &lt;--&gt; (2,1) ; &lt;ADJLIST_END&gt; &lt;ORIGIN_START&gt; (1,2) &lt;ORIGIN_END&gt; &lt;TARGET_START&gt; (0,0) &lt;TARGET_END&gt; &lt;PATH_START&gt; (1,2) (2,2) (2,1) (2,0) (1,0) (0,0) &lt;PATH_END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOP(UT(), AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=1), ConnectionEdges(walls=F), RandomCoords()), StepSequence(Singles(), step_tokenizers=(Coord(), ), pre=F, intra=F, post=F))</td>\n",
       "      <td>&lt;ADJLIST_START&gt; (1,0) &lt;--&gt; (0,0) ; (1,1) &lt;--&gt; (0,1) ; (1,2) &lt;--&gt; (0,2) ; (2,0) &lt;--&gt; (1,0) ; (2,2) &lt;--&gt; (1,2) ; (1,2) &lt;--&gt; (1,1) ; (2,1) &lt;--&gt; (2,0) ; (2,2) &lt;--&gt; (2,1) ; &lt;ADJLIST_END&gt; &lt;ORIGIN_START&gt; (1,2) &lt;ORIGIN_END&gt; &lt;TARGET_START&gt; &lt;TARGET_END&gt; &lt;PATH_START&gt; (1,2) (2,2) (2,1) (2,0) (1,0) (0,0) &lt;PATH_END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                          TokenizerElement  \\\n",
       "0  AOTP(UT(), AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=1), ConnectionEdges(walls=F), RandomCoords()), Unlabeled(post=F), StepSequence(Singles(), step_tokenizers=(Coord(), ), pre=F, intra=F, post=F))   \n",
       "1                      AOP(UT(), AdjListCoord(pre=F, post=T, shuffle_d0=T, Ungrouped(connection_token_ordinal=1), ConnectionEdges(walls=F), RandomCoords()), StepSequence(Singles(), step_tokenizers=(Coord(), ), pre=F, intra=F, post=F))   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                  tokens  \n",
       "0  <ADJLIST_START> (1,0) <--> (0,0) ; (1,1) <--> (0,1) ; (1,2) <--> (0,2) ; (2,0) <--> (1,0) ; (2,2) <--> (1,2) ; (1,2) <--> (1,1) ; (2,1) <--> (2,0) ; (2,2) <--> (2,1) ; <ADJLIST_END> <ORIGIN_START> (1,2) <ORIGIN_END> <TARGET_START> (0,0) <TARGET_END> <PATH_START> (1,2) (2,2) (2,1) (2,0) (1,0) (0,0) <PATH_END>  \n",
       "1        <ADJLIST_START> (1,0) <--> (0,0) ; (1,1) <--> (0,1) ; (1,2) <--> (0,2) ; (2,0) <--> (1,0) ; (2,2) <--> (1,2) ; (1,2) <--> (1,1) ; (2,1) <--> (2,0) ; (2,2) <--> (2,1) ; <ADJLIST_END> <ORIGIN_START> (1,2) <ORIGIN_END> <TARGET_START> <TARGET_END> <PATH_START> (1,2) (2,2) (2,1) (2,0) (1,0) (0,0) <PATH_END>  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_sequencers = [PromptSequencers.AOTP(), PromptSequencers.AOP()]\n",
    "columns = [\"_TokenizerElement\", \"tokens\"]\n",
    "tokenizers: pd.DataFrame = pd.DataFrame(columns=columns)\n",
    "\n",
    "tokenizers[\"_TokenizerElement\"] = prompt_sequencers\n",
    "tokenizers[\"tokens\"] = tokenizers[\"_TokenizerElement\"].apply(lambda x: \" \".join(x.to_tokens(maze=mz)))\n",
    "tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sample of `MazeTokenizerModular`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_size: int = 1_000\n",
    "\n",
    "tokenizers: list[MazeTokenizerModular] = random.sample(get_all_tokenizers(), random_sample_size)\n",
    "columns = [\"MazeTokenizerModular\", \"tokens\", \"encoding\", *mt_default.summary().keys()]\n",
    "df: pd.DataFrame = pd.DataFrame(columns=columns)\n",
    "\n",
    "df[\"MazeTokenizerModular\"] = tokenizers\n",
    "df[\"tokens\"] = df[\"MazeTokenizerModular\"].apply(lambda x: \" \".join(x.to_tokens(maze=mz)))\n",
    "df.encoding = df.tokens.apply(MazeTokenizerModular.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizers: 100%|| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MazeTokenizerModular</th>\n",
       "      <th>tokens</th>\n",
       "      <th>encoding</th>\n",
       "      <th>prompt_sequencer</th>\n",
       "      <th>coord_tokenizer</th>\n",
       "      <th>adj_list_tokenizer</th>\n",
       "      <th>edge_grouping</th>\n",
       "      <th>edge_subset</th>\n",
       "      <th>edge_permuter</th>\n",
       "      <th>target_tokenizer</th>\n",
       "      <th>path_tokenizer</th>\n",
       "      <th>step_size</th>\n",
       "      <th>step_tokenizers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; ( 0 , 0 &lt;--&gt; ( 1 , 0 ; ( 0 , 1...</td>\n",
       "      <td>[0, 11, 320, 12, 320, 8, 11, 321, 12, 320, 9, ...</td>\n",
       "      <td>AOTP(CTT(pre=T, intra=T, post=F), AdjListCoord...</td>\n",
       "      <td>CTT(pre=T, intra=T, post=F)</td>\n",
       "      <td>AdjListCoord(pre=F, post=T, shuffle_d0=F, Ungr...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=1)</td>\n",
       "      <td>ConnectionEdges(walls=F)</td>\n",
       "      <td>SortedCoords()</td>\n",
       "      <td>Unlabeled(post=F)</td>\n",
       "      <td>StepSequence(Forks(), step_tokenizers=(Coord()...</td>\n",
       "      <td>Forks()</td>\n",
       "      <td>Coord()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; ( 0 0 ) ( 0 1 ) &lt;XX&gt; ( 0 0 ) (...</td>\n",
       "      <td>[0, 11, 320, 320, 13, 11, 320, 321, 13, 707, 1...</td>\n",
       "      <td>AOP(CTT(pre=T, intra=F, post=T), AdjListCoord(...</td>\n",
       "      <td>CTT(pre=T, intra=F, post=T)</td>\n",
       "      <td>AdjListCoord(pre=F, post=F, shuffle_d0=T, Ungr...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=2)</td>\n",
       "      <td>AllLatticeEdges()</td>\n",
       "      <td>SortedCoords()</td>\n",
       "      <td>None</td>\n",
       "      <td>StepSequence(Forks(), step_tokenizers=(Coord()...</td>\n",
       "      <td>Forks()</td>\n",
       "      <td>Coord()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; (0,0) &lt;XX&gt; EAST (0,1) &lt;XX&gt; EAS...</td>\n",
       "      <td>[0, 1596, 707, 57, 1597, 707, 57, 1598, 707, 5...</td>\n",
       "      <td>AOTP(UT(), AdjListCardinal(pre=F, post=F, shuf...</td>\n",
       "      <td>UT()</td>\n",
       "      <td>AdjListCardinal(pre=F, post=F, shuffle_d0=T, U...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=1)</td>\n",
       "      <td>AllLatticeEdges()</td>\n",
       "      <td>BothCoords()</td>\n",
       "      <td>Unlabeled(post=F)</td>\n",
       "      <td>StepSequence(Singles(), step_tokenizers=(Coord...</td>\n",
       "      <td>Singles()</td>\n",
       "      <td>Coord()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; &lt;XX&gt; (0,0) EAST &lt;--&gt; (0,0) SOU...</td>\n",
       "      <td>[0, 707, 1596, 57, 8, 1596, 56, 707, 1597, 57,...</td>\n",
       "      <td>AOTP(UT(), AdjListCardinal(pre=F, post=F, shuf...</td>\n",
       "      <td>UT()</td>\n",
       "      <td>AdjListCardinal(pre=F, post=F, shuffle_d0=T, U...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=0)</td>\n",
       "      <td>AllLatticeEdges()</td>\n",
       "      <td>SortedCoords()</td>\n",
       "      <td>Unlabeled(post=F)</td>\n",
       "      <td>StepSequence(Singles(), step_tokenizers=(Dista...</td>\n",
       "      <td>Singles()</td>\n",
       "      <td>Coord()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; ( 0 , 0 ( 1 , 0 &lt;--&gt; ( 0 , 1 (...</td>\n",
       "      <td>[0, 11, 320, 12, 320, 11, 321, 12, 320, 8, 11,...</td>\n",
       "      <td>AOTP(CTT(pre=T, intra=T, post=F), AdjListCoord...</td>\n",
       "      <td>CTT(pre=T, intra=T, post=F)</td>\n",
       "      <td>AdjListCoord(pre=F, post=F, shuffle_d0=T, Ungr...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=2)</td>\n",
       "      <td>ConnectionEdges(walls=F)</td>\n",
       "      <td>RandomCoords()</td>\n",
       "      <td>Unlabeled(post=F)</td>\n",
       "      <td>StepSequence(Singles(), step_tokenizers=(Dista...</td>\n",
       "      <td>Singles()</td>\n",
       "      <td>Coord()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; ( 0 , 0 SOUTH &lt;--&gt; ; ( 0 , 1 S...</td>\n",
       "      <td>[0, 11, 320, 12, 320, 56, 8, 9, 11, 320, 12, 3...</td>\n",
       "      <td>AOTP(CTT(pre=T, intra=T, post=F), AdjListCardi...</td>\n",
       "      <td>CTT(pre=T, intra=T, post=F)</td>\n",
       "      <td>AdjListCardinal(pre=F, post=T, shuffle_d0=F, U...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=2)</td>\n",
       "      <td>ConnectionEdges(walls=F)</td>\n",
       "      <td>SortedCoords()</td>\n",
       "      <td>Unlabeled(post=F)</td>\n",
       "      <td>StepSequence(Singles(), step_tokenizers=(Dista...</td>\n",
       "      <td>Singles()</td>\n",
       "      <td>Coord()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; &lt;--&gt; 1 , 0 ) NORTH &lt;--&gt; 1 , 1 ...</td>\n",
       "      <td>[0, 8, 321, 12, 320, 13, 55, 8, 321, 12, 321, ...</td>\n",
       "      <td>AOTP(CTT(pre=F, intra=T, post=T), AdjListCardi...</td>\n",
       "      <td>CTT(pre=F, intra=T, post=T)</td>\n",
       "      <td>AdjListCardinal(pre=F, post=F, shuffle_d0=F, U...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=0)</td>\n",
       "      <td>ConnectionEdges(walls=F)</td>\n",
       "      <td>RandomCoords()</td>\n",
       "      <td>Unlabeled(post=F)</td>\n",
       "      <td>StepSequence(Forks(), step_tokenizers=(Distanc...</td>\n",
       "      <td>Forks()</td>\n",
       "      <td>Coord()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; 0 , 1 ) WEST &lt;XX&gt; 0 , 2 ) WEST...</td>\n",
       "      <td>[0, 320, 12, 321, 13, 58, 707, 320, 12, 322, 1...</td>\n",
       "      <td>AOP(CTT(pre=F, intra=T, post=T), AdjListCardin...</td>\n",
       "      <td>CTT(pre=F, intra=T, post=T)</td>\n",
       "      <td>AdjListCardinal(pre=F, post=F, shuffle_d0=T, U...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=2)</td>\n",
       "      <td>AllLatticeEdges()</td>\n",
       "      <td>RandomCoords()</td>\n",
       "      <td>None</td>\n",
       "      <td>StepSequence(Forks(), step_tokenizers=(Coord()...</td>\n",
       "      <td>Forks()</td>\n",
       "      <td>Distance()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; &lt;XX&gt; (0,1) WEST ; &lt;XX&gt; (0,2) W...</td>\n",
       "      <td>[0, 707, 1597, 58, 9, 707, 1600, 58, 9, 707, 1...</td>\n",
       "      <td>AOTP(UT(), AdjListCardinal(pre=F, post=T, shuf...</td>\n",
       "      <td>UT()</td>\n",
       "      <td>AdjListCardinal(pre=F, post=T, shuffle_d0=F, U...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=0)</td>\n",
       "      <td>AllLatticeEdges()</td>\n",
       "      <td>RandomCoords()</td>\n",
       "      <td>Unlabeled(post=F)</td>\n",
       "      <td>StepSequence(Singles(), step_tokenizers=(Dista...</td>\n",
       "      <td>Singles()</td>\n",
       "      <td>Coord()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>MazeTokenizerModular(prompt_sequencer=PromptSe...</td>\n",
       "      <td>&lt;ADJLIST_START&gt; 0 0 &lt;XX&gt; 0 1 0 0 &lt;--&gt; 1 0 0 1 ...</td>\n",
       "      <td>[0, 320, 320, 707, 320, 321, 320, 320, 8, 321,...</td>\n",
       "      <td>AOTP(CTT(pre=F, intra=F, post=F), AdjListCoord...</td>\n",
       "      <td>CTT(pre=F, intra=F, post=F)</td>\n",
       "      <td>AdjListCoord(pre=F, post=F, shuffle_d0=T, Ungr...</td>\n",
       "      <td>Ungrouped(connection_token_ordinal=1)</td>\n",
       "      <td>AllLatticeEdges()</td>\n",
       "      <td>SortedCoords()</td>\n",
       "      <td>Unlabeled(post=T)</td>\n",
       "      <td>StepSequence(Forks(), step_tokenizers=(Coord()...</td>\n",
       "      <td>Forks()</td>\n",
       "      <td>Distance()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MazeTokenizerModular  \\\n",
       "0    MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "1    MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "2    MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "3    MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "4    MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "..                                                 ...   \n",
       "995  MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "996  MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "997  MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "998  MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "999  MazeTokenizerModular(prompt_sequencer=PromptSe...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    <ADJLIST_START> ( 0 , 0 <--> ( 1 , 0 ; ( 0 , 1...   \n",
       "1    <ADJLIST_START> ( 0 0 ) ( 0 1 ) <XX> ( 0 0 ) (...   \n",
       "2    <ADJLIST_START> (0,0) <XX> EAST (0,1) <XX> EAS...   \n",
       "3    <ADJLIST_START> <XX> (0,0) EAST <--> (0,0) SOU...   \n",
       "4    <ADJLIST_START> ( 0 , 0 ( 1 , 0 <--> ( 0 , 1 (...   \n",
       "..                                                 ...   \n",
       "995  <ADJLIST_START> ( 0 , 0 SOUTH <--> ; ( 0 , 1 S...   \n",
       "996  <ADJLIST_START> <--> 1 , 0 ) NORTH <--> 1 , 1 ...   \n",
       "997  <ADJLIST_START> 0 , 1 ) WEST <XX> 0 , 2 ) WEST...   \n",
       "998  <ADJLIST_START> <XX> (0,1) WEST ; <XX> (0,2) W...   \n",
       "999  <ADJLIST_START> 0 0 <XX> 0 1 0 0 <--> 1 0 0 1 ...   \n",
       "\n",
       "                                              encoding  \\\n",
       "0    [0, 11, 320, 12, 320, 8, 11, 321, 12, 320, 9, ...   \n",
       "1    [0, 11, 320, 320, 13, 11, 320, 321, 13, 707, 1...   \n",
       "2    [0, 1596, 707, 57, 1597, 707, 57, 1598, 707, 5...   \n",
       "3    [0, 707, 1596, 57, 8, 1596, 56, 707, 1597, 57,...   \n",
       "4    [0, 11, 320, 12, 320, 11, 321, 12, 320, 8, 11,...   \n",
       "..                                                 ...   \n",
       "995  [0, 11, 320, 12, 320, 56, 8, 9, 11, 320, 12, 3...   \n",
       "996  [0, 8, 321, 12, 320, 13, 55, 8, 321, 12, 321, ...   \n",
       "997  [0, 320, 12, 321, 13, 58, 707, 320, 12, 322, 1...   \n",
       "998  [0, 707, 1597, 58, 9, 707, 1600, 58, 9, 707, 1...   \n",
       "999  [0, 320, 320, 707, 320, 321, 320, 320, 8, 321,...   \n",
       "\n",
       "                                      prompt_sequencer  \\\n",
       "0    AOTP(CTT(pre=T, intra=T, post=F), AdjListCoord...   \n",
       "1    AOP(CTT(pre=T, intra=F, post=T), AdjListCoord(...   \n",
       "2    AOTP(UT(), AdjListCardinal(pre=F, post=F, shuf...   \n",
       "3    AOTP(UT(), AdjListCardinal(pre=F, post=F, shuf...   \n",
       "4    AOTP(CTT(pre=T, intra=T, post=F), AdjListCoord...   \n",
       "..                                                 ...   \n",
       "995  AOTP(CTT(pre=T, intra=T, post=F), AdjListCardi...   \n",
       "996  AOTP(CTT(pre=F, intra=T, post=T), AdjListCardi...   \n",
       "997  AOP(CTT(pre=F, intra=T, post=T), AdjListCardin...   \n",
       "998  AOTP(UT(), AdjListCardinal(pre=F, post=T, shuf...   \n",
       "999  AOTP(CTT(pre=F, intra=F, post=F), AdjListCoord...   \n",
       "\n",
       "                 coord_tokenizer  \\\n",
       "0    CTT(pre=T, intra=T, post=F)   \n",
       "1    CTT(pre=T, intra=F, post=T)   \n",
       "2                           UT()   \n",
       "3                           UT()   \n",
       "4    CTT(pre=T, intra=T, post=F)   \n",
       "..                           ...   \n",
       "995  CTT(pre=T, intra=T, post=F)   \n",
       "996  CTT(pre=F, intra=T, post=T)   \n",
       "997  CTT(pre=F, intra=T, post=T)   \n",
       "998                         UT()   \n",
       "999  CTT(pre=F, intra=F, post=F)   \n",
       "\n",
       "                                    adj_list_tokenizer  \\\n",
       "0    AdjListCoord(pre=F, post=T, shuffle_d0=F, Ungr...   \n",
       "1    AdjListCoord(pre=F, post=F, shuffle_d0=T, Ungr...   \n",
       "2    AdjListCardinal(pre=F, post=F, shuffle_d0=T, U...   \n",
       "3    AdjListCardinal(pre=F, post=F, shuffle_d0=T, U...   \n",
       "4    AdjListCoord(pre=F, post=F, shuffle_d0=T, Ungr...   \n",
       "..                                                 ...   \n",
       "995  AdjListCardinal(pre=F, post=T, shuffle_d0=F, U...   \n",
       "996  AdjListCardinal(pre=F, post=F, shuffle_d0=F, U...   \n",
       "997  AdjListCardinal(pre=F, post=F, shuffle_d0=T, U...   \n",
       "998  AdjListCardinal(pre=F, post=T, shuffle_d0=F, U...   \n",
       "999  AdjListCoord(pre=F, post=F, shuffle_d0=T, Ungr...   \n",
       "\n",
       "                             edge_grouping               edge_subset  \\\n",
       "0    Ungrouped(connection_token_ordinal=1)  ConnectionEdges(walls=F)   \n",
       "1    Ungrouped(connection_token_ordinal=2)         AllLatticeEdges()   \n",
       "2    Ungrouped(connection_token_ordinal=1)         AllLatticeEdges()   \n",
       "3    Ungrouped(connection_token_ordinal=0)         AllLatticeEdges()   \n",
       "4    Ungrouped(connection_token_ordinal=2)  ConnectionEdges(walls=F)   \n",
       "..                                     ...                       ...   \n",
       "995  Ungrouped(connection_token_ordinal=2)  ConnectionEdges(walls=F)   \n",
       "996  Ungrouped(connection_token_ordinal=0)  ConnectionEdges(walls=F)   \n",
       "997  Ungrouped(connection_token_ordinal=2)         AllLatticeEdges()   \n",
       "998  Ungrouped(connection_token_ordinal=0)         AllLatticeEdges()   \n",
       "999  Ungrouped(connection_token_ordinal=1)         AllLatticeEdges()   \n",
       "\n",
       "      edge_permuter   target_tokenizer  \\\n",
       "0    SortedCoords()  Unlabeled(post=F)   \n",
       "1    SortedCoords()               None   \n",
       "2      BothCoords()  Unlabeled(post=F)   \n",
       "3    SortedCoords()  Unlabeled(post=F)   \n",
       "4    RandomCoords()  Unlabeled(post=F)   \n",
       "..              ...                ...   \n",
       "995  SortedCoords()  Unlabeled(post=F)   \n",
       "996  RandomCoords()  Unlabeled(post=F)   \n",
       "997  RandomCoords()               None   \n",
       "998  RandomCoords()  Unlabeled(post=F)   \n",
       "999  SortedCoords()  Unlabeled(post=T)   \n",
       "\n",
       "                                        path_tokenizer  step_size  \\\n",
       "0    StepSequence(Forks(), step_tokenizers=(Coord()...    Forks()   \n",
       "1    StepSequence(Forks(), step_tokenizers=(Coord()...    Forks()   \n",
       "2    StepSequence(Singles(), step_tokenizers=(Coord...  Singles()   \n",
       "3    StepSequence(Singles(), step_tokenizers=(Dista...  Singles()   \n",
       "4    StepSequence(Singles(), step_tokenizers=(Dista...  Singles()   \n",
       "..                                                 ...        ...   \n",
       "995  StepSequence(Singles(), step_tokenizers=(Dista...  Singles()   \n",
       "996  StepSequence(Forks(), step_tokenizers=(Distanc...    Forks()   \n",
       "997  StepSequence(Forks(), step_tokenizers=(Coord()...    Forks()   \n",
       "998  StepSequence(Singles(), step_tokenizers=(Dista...  Singles()   \n",
       "999  StepSequence(Forks(), step_tokenizers=(Coord()...    Forks()   \n",
       "\n",
       "    step_tokenizers  \n",
       "0           Coord()  \n",
       "1           Coord()  \n",
       "2           Coord()  \n",
       "3           Coord()  \n",
       "4           Coord()  \n",
       "..              ...  \n",
       "995         Coord()  \n",
       "996         Coord()  \n",
       "997      Distance()  \n",
       "998         Coord()  \n",
       "999      Distance()  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for k in tqdm(mt_default.summary().keys(), desc=\"Tokenizers\", total=len(mt_default.summary())):\n",
    "    df[k] = df.apply(lambda x: x.MazeTokenizerModular.summary()[k] if k in x.MazeTokenizerModular.summary() else None, axis=1)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze-dataset-zQQMZP3O-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
