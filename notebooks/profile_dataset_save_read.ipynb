{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile of `maze_dataset` Dumping and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytest\n",
    "\n",
    "from maze_dataset.dataset.maze_dataset import (\n",
    "    MazeDataset,\n",
    "    MazeDatasetConfig,\n",
    ")\n",
    "from maze_dataset.generation.generators import GENERATORS_MAP\n",
    "\n",
    "from maze_dataset.utils import timeit_fancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs: list[MazeDatasetConfig] = [\n",
    "    MazeDatasetConfig(name=\"test\", **kwargs)\n",
    "    for kwargs in [\n",
    "\t\tdict(grid_n=3, n_mazes=1, maze_ctor=GENERATORS_MAP['gen_dfs'], maze_ctor_kwargs={}, serialize_minimal_threshold=1),\n",
    "\t\tdict(grid_n=5, n_mazes=10, maze_ctor=GENERATORS_MAP['gen_dfs'], maze_ctor_kwargs=dict(do_forks=False), serialize_minimal_threshold=None),\n",
    "\t\tdict(grid_n=10, n_mazes=100, maze_ctor=GENERATORS_MAP['gen_dfs'], maze_ctor_kwargs={}, serialize_minimal_threshold=None),\n",
    "\t\tdict(grid_n=5, n_mazes=10, maze_ctor=GENERATORS_MAP['gen_dfs'], maze_ctor_kwargs={}, serialize_minimal_threshold=None),\n",
    "\t\tdict(grid_n=5, n_mazes=100, maze_ctor=GENERATORS_MAP['gen_dfs'], maze_ctor_kwargs={}, serialize_minimal_threshold=None),\n",
    "\t\tdict(grid_n=5, n_mazes=1000, maze_ctor=GENERATORS_MAP['gen_dfs'], maze_ctor_kwargs={}, serialize_minimal_threshold=None),\n",
    "    ]\n",
    "]\n",
    "\n",
    "datasets: list[MazeDataset] = [MazeDataset.generate(cfg) for cfg in cfgs]\n",
    "old_len_cfgs: int = len(cfgs)  # Used in section for large dataset profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns: list[str] = ['grid_n', 'n_mazes', 'serialize', 'serialize_minimal', 'load', 'load_minimal', 'save', 'save_minimal', 'read', 'read_minimal']\n",
    "speeds_data: list[dict] = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_dataset_speed(d: MazeDataset) -> dict:\n",
    "    # set up row data\n",
    "    row_data: dict = dict(\n",
    "        grid_n=d.cfg.grid_n,\n",
    "        n_mazes=d.cfg.n_mazes,\n",
    "    )\n",
    "    # serialization & loading\n",
    "    d.cfg.serialize_minimal_threshold = None\n",
    "    row_data['serialize'], ser_default = timeit_fancy(d.serialize, get_return=True)\n",
    "    row_data['serialize_minimal'], ser_min = timeit_fancy(d.serialize_minimal, get_return=True)\n",
    "    row_data['load'] = timeit_fancy(lambda: MazeDataset.load(ser_default))\n",
    "    row_data['load_minimal'] = timeit_fancy(lambda: MazeDataset.load(ser_min))\n",
    "\n",
    "    # saving and loading\n",
    "    path_default: str = f'../data/{d.cfg.to_fname()}.zanj'\n",
    "    path_min: str = f'../data/{d.cfg.to_fname()}_min.zanj'\n",
    "\n",
    "    # default\n",
    "    d.cfg.serialize_minimal_threshold = None\n",
    "    row_data['save'] = timeit_fancy(lambda: d.save(file_path=path_default))\n",
    "    row_data['read'], read_default = timeit_fancy(lambda: MazeDataset.read(file_path=path_default), get_return=True)\n",
    "    # minimal\n",
    "    d.cfg.serialize_minimal_threshold = 0\n",
    "    row_data['save_minimal'] = timeit_fancy(lambda: d.save(file_path=path_min))\n",
    "    row_data['read_minimal'], read_minimal = timeit_fancy(lambda: MazeDataset.read(file_path=path_min), get_return=True)\n",
    "\n",
    "    # asserts\n",
    "    # assert d == read_default\n",
    "    # assert d == read_minimal\n",
    "\n",
    "    # reset cfg?\n",
    "    d.cfg.serialize_minimal_threshold = None\n",
    "\n",
    "    return row_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile small datasets only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling: MazeDatasetConfig(name='test', seq_len_min=1, seq_len_max=512, seed=42, applied_filters=[], grid_n=3, n_mazes=1, maze_ctor=<function LatticeMazeGenerators.gen_dfs at 0x0000017A67C6BD80>, maze_ctor_kwargs={}, serialize_minimal_threshold=1)\n",
      "Profiling: MazeDatasetConfig(name='test', seq_len_min=1, seq_len_max=512, seed=42, applied_filters=[], grid_n=5, n_mazes=10, maze_ctor=<function LatticeMazeGenerators.gen_dfs at 0x0000017A67C6BD80>, maze_ctor_kwargs={'do_forks': False}, serialize_minimal_threshold=None)\n",
      "Profiling: MazeDatasetConfig(name='test', seq_len_min=1, seq_len_max=512, seed=42, applied_filters=[], grid_n=10, n_mazes=100, maze_ctor=<function LatticeMazeGenerators.gen_dfs at 0x0000017A67C6BD80>, maze_ctor_kwargs={}, serialize_minimal_threshold=None)\n",
      "Profiling: MazeDatasetConfig(name='test', seq_len_min=1, seq_len_max=512, seed=42, applied_filters=[], grid_n=5, n_mazes=10, maze_ctor=<function LatticeMazeGenerators.gen_dfs at 0x0000017A67C6BD80>, maze_ctor_kwargs={}, serialize_minimal_threshold=None)\n",
      "Profiling: MazeDatasetConfig(name='test', seq_len_min=1, seq_len_max=512, seed=42, applied_filters=[], grid_n=5, n_mazes=100, maze_ctor=<function LatticeMazeGenerators.gen_dfs at 0x0000017A67C6BD80>, maze_ctor_kwargs={}, serialize_minimal_threshold=None)\n",
      "Profiling: MazeDatasetConfig(name='test', seq_len_min=1, seq_len_max=512, seed=42, applied_filters=[], grid_n=5, n_mazes=1000, maze_ctor=<function LatticeMazeGenerators.gen_dfs at 0x0000017A67C6BD80>, maze_ctor_kwargs={}, serialize_minimal_threshold=None)\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(datasets):\n",
    "    print(f'Profiling: {d.cfg}')\n",
    "    speeds_data.append(measure_dataset_speed(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEEDS: pd.DataFrame = pd.DataFrame(speeds_data, columns=columns)\n",
    "\n",
    "def compute_speedups(speeds: pd.DataFrame, column_measurement_prefixes: list[str] = ['serialize', 'load', 'save', 'read']) -> pd.DataFrame:\n",
    "    for prefix in column_measurement_prefixes:\n",
    "        speeds[f'{prefix}_speedup'] = speeds[f'{prefix}'] / speeds[f'{prefix}_minimal']\n",
    "    return speeds\n",
    "\n",
    "SPEEDS = compute_speedups(SPEEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_n</th>\n",
       "      <th>n_mazes</th>\n",
       "      <th>serialize</th>\n",
       "      <th>serialize_minimal</th>\n",
       "      <th>load</th>\n",
       "      <th>load_minimal</th>\n",
       "      <th>save</th>\n",
       "      <th>save_minimal</th>\n",
       "      <th>read</th>\n",
       "      <th>read_minimal</th>\n",
       "      <th>serialize_speedup</th>\n",
       "      <th>load_speedup</th>\n",
       "      <th>save_speedup</th>\n",
       "      <th>read_speedup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>0.011121</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>0.024423</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.387763</td>\n",
       "      <td>0.965631</td>\n",
       "      <td>0.861929</td>\n",
       "      <td>0.867272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.012284</td>\n",
       "      <td>0.011208</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>0.026598</td>\n",
       "      <td>0.016718</td>\n",
       "      <td>0.015396</td>\n",
       "      <td>0.323517</td>\n",
       "      <td>1.095967</td>\n",
       "      <td>0.983468</td>\n",
       "      <td>1.085884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>0.020319</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.247172</td>\n",
       "      <td>0.038152</td>\n",
       "      <td>0.218833</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.149940</td>\n",
       "      <td>2.479256</td>\n",
       "      <td>6.478559</td>\n",
       "      <td>19.048197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>0.025777</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>0.015148</td>\n",
       "      <td>0.327740</td>\n",
       "      <td>1.088690</td>\n",
       "      <td>1.117426</td>\n",
       "      <td>1.281563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.014078</td>\n",
       "      <td>0.019727</td>\n",
       "      <td>0.007572</td>\n",
       "      <td>0.099197</td>\n",
       "      <td>0.033793</td>\n",
       "      <td>0.072562</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.157862</td>\n",
       "      <td>2.605390</td>\n",
       "      <td>2.935398</td>\n",
       "      <td>6.992113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.095593</td>\n",
       "      <td>0.143195</td>\n",
       "      <td>0.017081</td>\n",
       "      <td>0.284849</td>\n",
       "      <td>0.125186</td>\n",
       "      <td>0.662439</td>\n",
       "      <td>0.019039</td>\n",
       "      <td>0.066646</td>\n",
       "      <td>8.383326</td>\n",
       "      <td>2.275415</td>\n",
       "      <td>34.794242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_n  n_mazes  serialize  serialize_minimal      load  load_minimal  \\\n",
       "0       3        1   0.001816           0.004684  0.010739      0.011121   \n",
       "1       5       10   0.001850           0.005718  0.012284      0.011208   \n",
       "2      10      100   0.002202           0.014688  0.020319      0.008195   \n",
       "3       5       10   0.001857           0.005665  0.012256      0.011258   \n",
       "4       5      100   0.002222           0.014078  0.019727      0.007572   \n",
       "5       5     1000   0.006371           0.095593  0.143195      0.017081   \n",
       "\n",
       "       save  save_minimal      read  read_minimal  serialize_speedup  \\\n",
       "0  0.021051      0.024423  0.012759      0.014712           0.387763   \n",
       "1  0.026159      0.026598  0.016718      0.015396           0.323517   \n",
       "2  0.247172      0.038152  0.218833      0.011488           0.149940   \n",
       "3  0.028804      0.025777  0.019413      0.015148           0.327740   \n",
       "4  0.099197      0.033793  0.072562      0.010378           0.157862   \n",
       "5  0.284849      0.125186  0.662439      0.019039           0.066646   \n",
       "\n",
       "   load_speedup  save_speedup  read_speedup  \n",
       "0      0.965631      0.861929      0.867272  \n",
       "1      1.095967      0.983468      1.085884  \n",
       "2      2.479256      6.478559     19.048197  \n",
       "3      1.088690      1.117426      1.281563  \n",
       "4      2.605390      2.935398      6.992113  \n",
       "5      8.383326      2.275415     34.794242  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "fig.subplots(2,2)\n",
    "ax = fig.axes[0]\n",
    "speeds.loc[3:, ['n_mazes', 'serialize', 'serialize_minimal']].plot(x='n_mazes', ax=ax, logx=True, logy=True)\n",
    "ax.set_ylabel('Runtime [sec]')\n",
    "\n",
    "ax = fig.axes[1]\n",
    "speeds.loc[3:, ['n_mazes', 'load', 'load_minimal']].plot(x='n_mazes', ax=ax, logx=True, logy=True)\n",
    "ax.set_ylabel('Runtime [sec]')\n",
    "\n",
    "ax = fig.axes[2]\n",
    "speeds.loc[3:, ['n_mazes', 'save', 'save_minimal']].plot(x='n_mazes', ax=ax, logx=True, logy=True)\n",
    "ax.set_ylabel('Runtime [sec]')\n",
    "\n",
    "ax = fig.axes[3]\n",
    "speeds.loc[3:, ['n_mazes', 'read', 'read_minimal']].plot(x='n_mazes', ax=ax, logx=True, logy=True)\n",
    "ax.set_ylabel('Runtime [sec]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile Large Datasets\n",
    "This section should be skipped during the CI autoruns since running timing on large datasets takes awhile. `exit` is called so that execution stops and the cell outputs below are preserved. The outputs are for reference and manual rerun after further updates to `serialize`, `load`, `save`, etc. To manually rerun with all the datasets, just comment out the cell below first. Run, then uncomment it again before merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs.extend(\n",
    "    [MazeDatasetConfig(name=\"test\", grid_n=grid_n, n_mazes=n_mazes, maze_ctor=maze_ctor, maze_ctor_kwargs=maze_ctor_kwargs, serialize_minimal_threshold=srz_threshold) \n",
    "        for grid_n, n_mazes, maze_ctor, maze_ctor_kwargs, srz_threshold in [\n",
    "            (5, 10000, GENERATORS_MAP['gen_dfs'], {}, None), \n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "datasets.extend([MazeDataset.generate(cfg) for cfg in cfgs[old_len_cfgs:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(datasets):\n",
    "    if i < old_len_cfgs: continue  # No need to rerun small datasets\n",
    "    print(d.cfg)\n",
    "    d.cfg.serialize_minimal_threshold = None\n",
    "    speeds.loc[i, 'serialize']        , s    = timeit_fancy(d.serialize, get_return=True)\n",
    "    speeds.loc[i, 'serialize_minimal'], smin = timeit_fancy(d.serialize_minimal, get_return=True)\n",
    "    speeds.loc[i, 'load']                    = timeit_fancy(lambda: MazeDataset.load(s))\n",
    "    speeds.loc[i, 'load_minimal']            = timeit_fancy(lambda: MazeDataset.load(smin))\n",
    "    p = os.path.abspath(os.path.join(os.getcwd(), '..', 'data',d.cfg.to_fname()+'.zanj'))\n",
    "    p_min = os.path.abspath(os.path.join(os.getcwd(), '..', 'data',d.cfg.to_fname()+'_min.zanj'))\n",
    "    speeds.loc[i, 'save']                    = timeit_fancy(lambda: d.save(file_path=p))\n",
    "    speeds.loc[i, 'read'], rt                = timeit_fancy(lambda: MazeDataset.read(file_path=p), get_return=True)\n",
    "    d.cfg.serialize_minimal_threshold = 1\n",
    "    speeds.loc[i, 'save_minimal']            = timeit_fancy(lambda: d.save(file_path=p_min))\n",
    "    speeds.loc[i, 'read_minimal'], rt_min    = timeit_fancy(lambda: MazeDataset.read(file_path=p_min), get_return=True)\n",
    "    d.cfg.serialize_minimal_threshold = None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds.grid_n = [c.grid_n for c in cfgs]\n",
    "speeds.n_mazes = [c.n_mazes for c in cfgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ind, max_n = np.argmax(speeds.n_mazes.values), np.max(speeds.n_mazes.values)\n",
    "print(f'{max_n} mazes:')\n",
    "for c_i in range(2, 10, 2):\n",
    "    advantage = speeds.iloc[max_ind, c_i] / speeds.iloc[max_ind, c_i+1]\n",
    "    print('`{}`: \\tminimal/standard speedup: {:3.1f}x'.format(speeds.columns[c_i], advantage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing rows 2 and 4, it appears that the `grid_n` has a relatively small effect on `serialize` and `load` runtimes. Those functions appear to run in $O(n_{\\mathrm{mazes}})$ time. `grid_n` does impact `save` and `read`, but not their `_minimal` counterparts as much.\n",
    "\n",
    "To compare the speed of analogous procedures vs `n_mazes`, the plots below show data from `speeds.loc[3:,:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "fig.subplots(2,2)\n",
    "ax = fig.axes[0]\n",
    "speeds.loc[3:, ['n_mazes', 'serialize', 'serialize_minimal']].plot(x='n_mazes', ax=ax, logx=True, logy=True)\n",
    "ax.set_ylabel('Runtime [sec]')\n",
    "\n",
    "ax = fig.axes[1]\n",
    "speeds.loc[3:, ['n_mazes', 'load', 'load_minimal']].plot(x='n_mazes', ax=ax, logx=True, logy=True)\n",
    "ax.set_ylabel('Runtime [sec]')\n",
    "\n",
    "ax = fig.axes[2]\n",
    "speeds.loc[3:, ['n_mazes', 'save', 'save_minimal']].plot(x='n_mazes', ax=ax, logx=True, logy=True)\n",
    "ax.set_ylabel('Runtime [sec]')\n",
    "\n",
    "ax = fig.axes[3]\n",
    "speeds.loc[3:, ['n_mazes', 'read', 'read_minimal']].plot(x='n_mazes', ax=ax, logx=True, logy=True)\n",
    "ax.set_ylabel('Runtime [sec]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
