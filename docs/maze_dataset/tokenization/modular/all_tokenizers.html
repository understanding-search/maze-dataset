<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.1"/>
    <title>maze_dataset.tokenization.modular.all_tokenizers API documentation</title>
<link rel="stylesheet" href="../../../resources/css/bootstrap-reboot.min.css"><link rel="stylesheet" href="../../../resources/css/syntax-highlighting.css"><link rel="stylesheet" href="../../../resources/css/theme.css"><link rel="stylesheet" href="../../../resources/css/layout.css"><link rel="stylesheet" href="../../../resources/css/content.css"><link rel="stylesheet" href="../../../resources/css/custom.css"><script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
    };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
    /* Re-invoke MathJax when DOM content changes, for example during search. */
    document.addEventListener("DOMContentLoaded", () => {
        new MutationObserver(() => MathJax.typeset()).observe(
            document.querySelector("main.pdoc").parentNode,
            {childList: true}
        );
    })
</script>
<style>
    mjx-container {
        overflow-x: auto;
        overflow-y: hidden;
    }
</style><style>
    .pdoc .mermaid-pre {
        border: none;
        background: none;
    }
</style>
<script type="module" defer>
    import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs";

    /* Re-invoke Mermaid when DOM content changes, for example during search. */
    document.addEventListener("DOMContentLoaded", () => {
        new MutationObserver(() => mermaid.run()).observe(
            document.querySelector("main.pdoc").parentNode,
            {childList: true}
        );
    })
</script></head>
<body>
<div class="package-version">
    docs for <a href="https://github.com/understanding-search/maze-dataset">maze-dataset</a> v1.3.0<br>
</div>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button">
            <img src="../../../resources/svg/navtoggle.svg" alt="Toggle navigation"> 
        </label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../modular.html">
                <img src="../../../resources/svg/box-arrow-in-left.svg" alt="Back to parent module"/>
                &nbsp;maze_dataset.tokenization.modular</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>

            <h2>Contents</h2>
            <ul>
  <li><a href="#get_all_tokenizers"><code>get_all_tokenizers()</code></a>
  <ul>
    <li><a href="#use-cases">Use Cases</a></li>
  </ul></li>
  <li><a href="#every_test_tokenizers"><code>EVERY_TEST_TOKENIZERS</code></a></li>
</ul>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="variable" href="#MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS">MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS</a>
            </li>
            <li>
                    <a class="variable" href="#DOWNLOAD_URL">DOWNLOAD_URL</a>
            </li>
            <li>
                    <a class="function" href="#get_all_tokenizers">get_all_tokenizers</a>
            </li>
            <li>
                    <a class="function" href="#get_all_tokenizers_names">get_all_tokenizers_names</a>
            </li>
            <li>
                    <a class="variable" href="#EVERY_TEST_TOKENIZERS">EVERY_TEST_TOKENIZERS</a>
            </li>
            <li>
                    <a class="function" href="#all_tokenizers_set">all_tokenizers_set</a>
            </li>
            <li>
                    <a class="function" href="#sample_all_tokenizers">sample_all_tokenizers</a>
            </li>
            <li>
                    <a class="function" href="#sample_tokenizers_for_test">sample_tokenizers_for_test</a>
            </li>
            <li>
                    <a class="function" href="#save_hashes">save_hashes</a>
            </li>
    </ul>


    <hr/>
    
    <div>
        <a href="../../../coverage/html/index.html" class="pdoc-button" title="View test coverage report">
            Coverage
        </a>
        <a href="../../../other/todo-inline.html" class="pdoc-button" title="Table of TODOs scraped from source code, with links to create issues from them">
            TODOs
        </a>
        <a href="../../../other/lmcat.txt" class="pdoc-button" title="a view of the repo contents made for LLMs, using https://miv.name/lmcat">
            lmcat
        </a>
    </div>


        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span>
            <img src="../../../resources/svg/pdoc-logo.svg" alt="pdoc logo"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                        <a class="pdoc-button git-button" href="https://github.com/understanding-search/maze-dataset/blob/1.3.0maze_dataset/tokenization/modular/all_tokenizers.py">View Source on GitHub</a>
                    <h1 class="modulename">
<a href="./../../../maze_dataset.html">maze_dataset</a><wbr>.<a href="./../../tokenization.html">tokenization</a><wbr>.<a href="./../modular.html">modular</a><wbr>.all_tokenizers    </h1>

                        <div class="docstring"><p>Contains <code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code> and supporting limited-use functions.</p>

<h1 id="get_all_tokenizers"><code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code></h1>

<p>returns a comprehensive collection of all valid <code>MazeTokenizerModular</code> objects.
This is an overwhelming majority subset of the set of all possible <code>MazeTokenizerModular</code> objects.
Other tokenizers not contained in <code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code> may be possible to construct, but they are untested and not guaranteed to work.
This collection is in a separate module since it is expensive to compute and will grow more expensive as features are added to <code>MazeTokenizerModular</code>.</p>

<h2 id="use-cases">Use Cases</h2>

<p>In general, uses for this module are limited to development of the library and specific research studying many tokenization behaviors.</p>

<ul>
<li>Unit testing:
<ul>
<li>Tokenizers to use in unit tests are sampled from <code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code></li>
</ul></li>
<li>Large-scale tokenizer research:
<ul>
<li>Specific research training models on many tokenization behaviors can use <code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code> as the maximally inclusive collection</li>
<li><code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code> may be subsequently filtered using <code>MazeTokenizerModular.has_element</code>
For other uses, it's likely that the computational expense can be avoided by using</li>
</ul></li>
<li><code>maze_tokenizer.get_all_tokenizer_hashes()</code> for membership checks</li>
<li><code>utils.all_instances</code> for generating smaller subsets of <code>MazeTokenizerModular</code> or <code>_TokenizerElement</code> objects</li>
</ul>

<h1 id="every_test_tokenizers"><code><a href="#EVERY_TEST_TOKENIZERS">EVERY_TEST_TOKENIZERS</a></code></h1>

<p>A collection of the tokenizers which should always be included in unit tests when test fuzzing is used.
This collection should be expanded as specific tokenizers become canonical or popular.</p>
</div>

                        <input id="mod-all_tokenizers-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="mod-all_tokenizers-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/understanding-search/maze-dataset/blob/1.3.0maze_dataset/tokenization/modular/all_tokenizers.py#L0-L218" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

                <br/>
                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="sd">&quot;&quot;&quot;Contains `get_all_tokenizers()` and supporting limited-use functions.</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a><span class="sd"># `get_all_tokenizers()`</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a><span class="sd">returns a comprehensive collection of all valid `MazeTokenizerModular` objects.</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a><span class="sd">This is an overwhelming majority subset of the set of all possible `MazeTokenizerModular` objects.</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a><span class="sd">Other tokenizers not contained in `get_all_tokenizers()` may be possible to construct, but they are untested and not guaranteed to work.</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a><span class="sd">This collection is in a separate module since it is expensive to compute and will grow more expensive as features are added to `MazeTokenizerModular`.</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a><span class="sd">## Use Cases</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a><span class="sd">In general, uses for this module are limited to development of the library and specific research studying many tokenization behaviors.</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a><span class="sd">- Unit testing:</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a><span class="sd">  - Tokenizers to use in unit tests are sampled from `get_all_tokenizers()`</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a><span class="sd">- Large-scale tokenizer research:</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a><span class="sd">  - Specific research training models on many tokenization behaviors can use `get_all_tokenizers()` as the maximally inclusive collection</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a><span class="sd">  - `get_all_tokenizers()` may be subsequently filtered using `MazeTokenizerModular.has_element`</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a><span class="sd">For other uses, it&#39;s likely that the computational expense can be avoided by using</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a><span class="sd">- `maze_tokenizer.get_all_tokenizer_hashes()` for membership checks</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a><span class="sd">- `utils.all_instances` for generating smaller subsets of `MazeTokenizerModular` or `_TokenizerElement` objects</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a><span class="sd"># `EVERY_TEST_TOKENIZERS`</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a><span class="sd">A collection of the tokenizers which should always be included in unit tests when test fuzzing is used.</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a><span class="sd">This collection should be expanded as specific tokenizers become canonical or popular.</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">multiprocessing</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">cache</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">frozendict</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">muutils.spinner</span><span class="w"> </span><span class="kn">import</span> <span class="n">NoOpContextManager</span><span class="p">,</span> <span class="n">SpinnerContext</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">maze_dataset.tokenization</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a>	<span class="n">CoordTokenizers</span><span class="p">,</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a>	<span class="n">MazeTokenizerModular</span><span class="p">,</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a>	<span class="n">PromptSequencers</span><span class="p">,</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a>	<span class="n">StepTokenizers</span><span class="p">,</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a>	<span class="n">_TokenizerElement</span><span class="p">,</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a><span class="p">)</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">maze_dataset.tokenization.modular.hashing</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a>	<span class="n">AllTokenizersHashBitLength</span><span class="p">,</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a>	<span class="n">AllTokenizersHashDtype</span><span class="p">,</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a>	<span class="n">AllTokenizersHashesArray</span><span class="p">,</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a><span class="p">)</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">maze_dataset.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">FiniteValued</span><span class="p">,</span> <span class="n">all_instances</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a><span class="c1"># Always include this as the first item in the dict `validation_funcs` whenever using `all_instances` with `MazeTokenizerModular`</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a><span class="c1"># TYPING: error: Type variable &quot;maze_dataset.utils.FiniteValued&quot; is unbound  [valid-type]</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a><span class="c1">#   note: (Hint: Use &quot;Generic[FiniteValued]&quot; or &quot;Protocol[FiniteValued]&quot; base class to bind &quot;FiniteValued&quot; inside a class)</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a><span class="c1">#   note: (Hint: Use &quot;FiniteValued&quot; in function signature to bind &quot;FiniteValued&quot; inside a function)</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a><span class="n">MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS</span><span class="p">:</span> <span class="n">frozendict</span><span class="o">.</span><span class="n">frozendict</span><span class="p">[</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a>	<span class="nb">type</span><span class="p">[</span><span class="n">FiniteValued</span><span class="p">],</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a>	<span class="n">Callable</span><span class="p">[[</span><span class="n">FiniteValued</span><span class="p">],</span> <span class="nb">bool</span><span class="p">],</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a><span class="p">]</span> <span class="o">=</span> <span class="n">frozendict</span><span class="o">.</span><span class="n">frozendict</span><span class="p">(</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a>	<span class="p">{</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a>		<span class="c1"># TYPING: Item &quot;bool&quot; of the upper bound &quot;bool | IsDataclass | Enum&quot; of type variable &quot;FiniteValued&quot; has no attribute &quot;is_valid&quot;  [union-attr]</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a>		<span class="n">_TokenizerElement</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">is_valid</span><span class="p">(),</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a>		<span class="c1"># Currently no need for `MazeTokenizerModular.is_valid` since that method contains no special cases not already covered by `_TokenizerElement.is_valid`</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a>		<span class="c1"># MazeTokenizerModular: lambda x: x.is_valid(),</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a>		<span class="c1"># TYPING: error: No overload variant of &quot;set&quot; matches argument type &quot;FiniteValued&quot;  [call-overload]</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a>		<span class="c1">#   note: Possible overload variants:</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a>		<span class="c1">#   note:     def [_T] set(self) -&gt; set[_T]</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a>		<span class="c1">#   note:     def [_T] set(self, Iterable[_T], /) -&gt; set[_T]</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a>		<span class="c1"># TYPING: error: Argument 1 to &quot;len&quot; has incompatible type &quot;FiniteValued&quot;; expected &quot;Sized&quot;  [arg-type]</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a>		<span class="n">StepTokenizers</span><span class="o">.</span><span class="n">StepTokenizerPermutation</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a>		<span class="ow">and</span> <span class="n">x</span> <span class="o">!=</span> <span class="p">(</span><span class="n">StepTokenizers</span><span class="o">.</span><span class="n">Distance</span><span class="p">(),),</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a>	<span class="p">},</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a><span class="p">)</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a><span class="n">DOWNLOAD_URL</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/understanding-search/maze-dataset/main/maze_dataset/tokenization/MazeTokenizerModular_hashes.npz&quot;</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a>
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a><span class="nd">@cache</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_all_tokenizers</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]:</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Computes a complete list of all valid tokenizers.</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a><span class="sd">	Warning: This is an expensive function.</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a>	<span class="k">return</span> <span class="nb">list</span><span class="p">(</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a>		<span class="n">all_instances</span><span class="p">(</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a>			<span class="n">MazeTokenizerModular</span><span class="p">,</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a>			<span class="n">validation_funcs</span><span class="o">=</span><span class="n">MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS</span><span class="p">,</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a>		<span class="p">),</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a>	<span class="p">)</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a><span class="nd">@cache</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_all_tokenizers_names</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;computes the sorted list of names of all tokenizers&quot;&quot;&quot;</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a>	<span class="k">return</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">tokenizer</span> <span class="ow">in</span> <span class="n">get_all_tokenizers</span><span class="p">()])</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a>	<span class="n">MazeTokenizerModular</span><span class="p">(),</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a>	<span class="n">MazeTokenizerModular</span><span class="p">(</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a>		<span class="n">prompt_sequencer</span><span class="o">=</span><span class="n">PromptSequencers</span><span class="o">.</span><span class="n">AOTP</span><span class="p">(</span><span class="n">coord_tokenizer</span><span class="o">=</span><span class="n">CoordTokenizers</span><span class="o">.</span><span class="n">CTT</span><span class="p">()),</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a>	<span class="p">),</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a>	<span class="c1"># TODO: add more here as specific tokenizers become canonical and frequently used</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a><span class="p">]</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a><span class="nd">@cache</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a><span class="k">def</span><span class="w"> </span><span class="nf">all_tokenizers_set</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">set</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]:</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Casts `get_all_tokenizers()` to a set.&quot;&quot;&quot;</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a>	<span class="k">return</span> <span class="nb">set</span><span class="p">(</span><span class="n">get_all_tokenizers</span><span class="p">())</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a><span class="nd">@cache</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a><span class="k">def</span><span class="w"> </span><span class="nf">_all_tokenizers_except_every_test_tokenizers</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]:</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Returns&quot;&quot;&quot;</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a>	<span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">all_tokenizers_set</span><span class="p">()</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">))</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a><span class="k">def</span><span class="w"> </span><span class="nf">sample_all_tokenizers</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]:</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Samples `n` tokenizers from `get_all_tokenizers()`.&quot;&quot;&quot;</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a>	<span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">get_all_tokenizers</span><span class="p">(),</span> <span class="n">n</span><span class="p">)</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a><span class="k">def</span><span class="w"> </span><span class="nf">sample_tokenizers_for_test</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]:</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Returns a sample of size `n` of unique elements from `get_all_tokenizers()`,</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a><span class="sd">	always including every element in `EVERY_TEST_TOKENIZERS`.</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a>	<span class="k">if</span> <span class="n">n</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a>		<span class="k">return</span> <span class="n">get_all_tokenizers</span><span class="p">()</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a>
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a>	<span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">):</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a>		<span class="n">err_msg</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;`n` must be at least </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">)</span><span class="w"> </span><span class="si">= }</span><span class="s2"> such that the sample can contain `EVERY_TEST_TOKENIZERS`.&quot;</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a>		<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a>			<span class="n">err_msg</span><span class="p">,</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a>		<span class="p">)</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a>	<span class="n">sample</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a>		<span class="n">_all_tokenizers_except_every_test_tokenizers</span><span class="p">(),</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a>		<span class="n">n</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">),</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a>	<span class="p">)</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a>	<span class="n">sample</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">)</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a>	<span class="k">return</span> <span class="n">sample</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a><span class="k">def</span><span class="w"> </span><span class="nf">save_hashes</span><span class="p">(</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a>	<span class="n">path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a>	<span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a>	<span class="n">parallelize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AllTokenizersHashesArray</span><span class="p">:</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Computes, sorts, and saves the hashes of every member of `get_all_tokenizers()`.&quot;&quot;&quot;</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a>	<span class="n">spinner</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a>		<span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">SpinnerContext</span><span class="p">,</span> <span class="n">spinner_chars</span><span class="o">=</span><span class="s2">&quot;square_dot&quot;</span><span class="p">)</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a>		<span class="k">if</span> <span class="n">verbose</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a>		<span class="k">else</span> <span class="n">NoOpContextManager</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a>	<span class="p">)</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a>	<span class="c1"># get all tokenizers</span>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a>	<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="s2">&quot;getting all tokenizers...&quot;</span><span class="p">,</span> <span class="n">update_interval</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a>		<span class="n">all_tokenizers</span> <span class="o">=</span> <span class="n">get_all_tokenizers</span><span class="p">()</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a>	<span class="c1"># compute hashes</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a>	<span class="n">hashes_array_np64</span><span class="p">:</span> <span class="n">AllTokenizersHashesArray</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a>	<span class="k">if</span> <span class="n">parallelize</span><span class="p">:</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a>		<span class="n">n_cpus</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a>			<span class="n">parallelize</span> <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">parallelize</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a>		<span class="p">)</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a>		<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span>  <span class="c1"># noqa: SIM117</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a>			<span class="n">initial_value</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;using </span><span class="si">{</span><span class="n">n_cpus</span><span class="si">}</span><span class="s2"> processes to compute </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">all_tokenizers</span><span class="p">)</span><span class="si">}</span><span class="s2"> tokenizer hashes...&quot;</span><span class="p">,</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a>			<span class="n">update_interval</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a>		<span class="p">):</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a>			<span class="k">with</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">n_cpus</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a>				<span class="n">hashes_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="nb">hash</span><span class="p">,</span> <span class="n">all_tokenizers</span><span class="p">))</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a>		<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="s2">&quot;converting hashes to numpy array...&quot;</span><span class="p">):</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a>			<span class="n">hashes_array_np64</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hashes_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a>		<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a>			<span class="n">initial_value</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;computing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">all_tokenizers</span><span class="p">)</span><span class="si">}</span><span class="s2"> tokenizer hashes...&quot;</span><span class="p">,</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a>		<span class="p">):</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>			<span class="n">hashes_array_np64</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a>				<span class="p">[</span>
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a>					<span class="nb">hash</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>  <span class="c1"># uses stable hash</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a>					<span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">all_tokenizers</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">)</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a>				<span class="p">],</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>				<span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>			<span class="p">)</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a>	<span class="c1"># convert to correct dtype</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>	<span class="n">hashes_array</span><span class="p">:</span> <span class="n">AllTokenizersHashesArray</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a>		<span class="n">hashes_array_np64</span> <span class="o">%</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">AllTokenizersHashBitLength</span><span class="p">)</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a>		<span class="k">if</span> <span class="n">AllTokenizersHashBitLength</span> <span class="o">&lt;</span> <span class="mi">64</span>  <span class="c1"># noqa: PLR2004</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a>		<span class="k">else</span> <span class="n">hashes_array_np64</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>	<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">AllTokenizersHashDtype</span><span class="p">)</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a>	<span class="c1"># make sure there are no dupes</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a>	<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="s2">&quot;sorting and checking for hash collisions...&quot;</span><span class="p">):</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a>		<span class="n">sorted_hashes</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">hashes_array</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a>		<span class="k">if</span> <span class="n">sorted_hashes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">hashes_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a>			<span class="n">collisions</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="n">sorted_hashes</span><span class="p">[</span><span class="n">counts</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a>			<span class="n">n_collisions</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">hashes_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">sorted_hashes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a>			<span class="n">err_msg</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a>				<span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">n_collisions</span><span class="si">}</span><span class="s2"> tokenizer hash collisions: </span><span class="si">{</span><span class="n">collisions</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a>				<span class="s2">&quot;Report error to the developer to increase the hash size or otherwise update the tokenizer hashing size:</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a>				<span class="sa">f</span><span class="s2">&quot;https://github.com/understanding-search/maze-dataset/issues/new?labels=bug,tokenization&amp;title=Tokenizer+hash+collision+error&amp;body=</span><span class="si">{</span><span class="n">n_collisions</span><span class="si">}</span><span class="s2">+collisions+out+of+</span><span class="si">{</span><span class="n">hashes_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">+total+hashes&quot;</span><span class="p">,</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a>			<span class="p">)</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a>			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a>				<span class="n">err_msg</span><span class="p">,</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a>			<span class="p">)</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a>	<span class="c1"># save and return</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a>	<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="s2">&quot;saving hashes...&quot;</span><span class="p">,</span> <span class="n">update_interval</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a>		<span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a>			<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="s2">&quot;MazeTokenizerModular_hashes.npz&quot;</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a>		<span class="n">np</span><span class="o">.</span><span class="n">savez_compressed</span><span class="p">(</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a>			<span class="n">path</span><span class="p">,</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a>			<span class="n">hashes</span><span class="o">=</span><span class="n">sorted_hashes</span><span class="p">,</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a>		<span class="p">)</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a>
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a>	<span class="k">return</span> <span class="n">sorted_hashes</span>
</span></pre></div>


                <br/>
            </section>
                <section id="MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS">
                    <div class="attr variable">
            <span class="name">MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS</span><span class="annotation">: frozendict.frozendict[type[~FiniteValued], typing.Callable[[~FiniteValued], bool]]</span>        =
<input id="MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS-view-value" class="view-value-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
            <label class="view-value-button pdoc-button" for="MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS-view-value"></label><span class="default_value">frozendict.frozendict({&lt;class &#39;maze_dataset.tokenization.modular.element_base._TokenizerElement&#39;&gt;: &lt;function &lt;lambda&gt;&gt;, tuple[maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer] | tuple[maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer, maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer] | tuple[maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer, maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer, maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer] | tuple[maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer, maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer, maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer, maze_dataset.tokenization.modular.elements.StepTokenizers._StepTokenizer]: &lt;function &lt;lambda&gt;&gt;})</span>

        
    </div>
    <a class="headerlink" href="#MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS"></a>
    
    

                </section>
                <section id="DOWNLOAD_URL">
                    <div class="attr variable">
            <span class="name">DOWNLOAD_URL</span><span class="annotation">: str</span>        =
<input id="DOWNLOAD_URL-view-value" class="view-value-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
            <label class="view-value-button pdoc-button" for="DOWNLOAD_URL-view-value"></label><span class="default_value">&#39;https://raw.githubusercontent.com/understanding-search/maze-dataset/main/maze_dataset/tokenization/MazeTokenizerModular_hashes.npz&#39;</span>

        
    </div>
    <a class="headerlink" href="#DOWNLOAD_URL"></a>
    
    

                </section>
                <section id="get_all_tokenizers">
                            <input id="get_all_tokenizers-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@cache</div>

        <span class="def">def</span>
        <span class="name">get_all_tokenizers</span><span class="signature pdoc-code multiline">(<span class="return-annotation">) -> <span class="nb">list</span><span class="p">[</span><span class="n"><a href="../../tokenization.html#MazeTokenizerModular">maze_dataset.tokenization.MazeTokenizerModular</a></span><span class="p">]</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="get_all_tokenizers-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/understanding-search/maze-dataset/blob/1.3.0maze_dataset/tokenization/modular/all_tokenizers.py#L77-L88" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#get_all_tokenizers"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_all_tokenizers-78"><a href="#get_all_tokenizers-78"><span class="linenos">78</span></a><span class="nd">@cache</span>
</span><span id="get_all_tokenizers-79"><a href="#get_all_tokenizers-79"><span class="linenos">79</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_all_tokenizers</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]:</span>
</span><span id="get_all_tokenizers-80"><a href="#get_all_tokenizers-80"><span class="linenos">80</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Computes a complete list of all valid tokenizers.</span>
</span><span id="get_all_tokenizers-81"><a href="#get_all_tokenizers-81"><span class="linenos">81</span></a>
</span><span id="get_all_tokenizers-82"><a href="#get_all_tokenizers-82"><span class="linenos">82</span></a><span class="sd">	Warning: This is an expensive function.</span>
</span><span id="get_all_tokenizers-83"><a href="#get_all_tokenizers-83"><span class="linenos">83</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="get_all_tokenizers-84"><a href="#get_all_tokenizers-84"><span class="linenos">84</span></a>	<span class="k">return</span> <span class="nb">list</span><span class="p">(</span>
</span><span id="get_all_tokenizers-85"><a href="#get_all_tokenizers-85"><span class="linenos">85</span></a>		<span class="n">all_instances</span><span class="p">(</span>
</span><span id="get_all_tokenizers-86"><a href="#get_all_tokenizers-86"><span class="linenos">86</span></a>			<span class="n">MazeTokenizerModular</span><span class="p">,</span>
</span><span id="get_all_tokenizers-87"><a href="#get_all_tokenizers-87"><span class="linenos">87</span></a>			<span class="n">validation_funcs</span><span class="o">=</span><span class="n">MAZE_TOKENIZER_MODULAR_DEFAULT_VALIDATION_FUNCS</span><span class="p">,</span>
</span><span id="get_all_tokenizers-88"><a href="#get_all_tokenizers-88"><span class="linenos">88</span></a>		<span class="p">),</span>
</span><span id="get_all_tokenizers-89"><a href="#get_all_tokenizers-89"><span class="linenos">89</span></a>	<span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Computes a complete list of all valid tokenizers.</p>

<p>Warning: This is an expensive function.</p>
</div>


                </section>
                <section id="get_all_tokenizers_names">
                            <input id="get_all_tokenizers_names-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@cache</div>

        <span class="def">def</span>
        <span class="name">get_all_tokenizers_names</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="get_all_tokenizers_names-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/understanding-search/maze-dataset/blob/1.3.0maze_dataset/tokenization/modular/all_tokenizers.py#L91-L94" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#get_all_tokenizers_names"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_all_tokenizers_names-92"><a href="#get_all_tokenizers_names-92"><span class="linenos">92</span></a><span class="nd">@cache</span>
</span><span id="get_all_tokenizers_names-93"><a href="#get_all_tokenizers_names-93"><span class="linenos">93</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_all_tokenizers_names</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="get_all_tokenizers_names-94"><a href="#get_all_tokenizers_names-94"><span class="linenos">94</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;computes the sorted list of names of all tokenizers&quot;&quot;&quot;</span>
</span><span id="get_all_tokenizers_names-95"><a href="#get_all_tokenizers_names-95"><span class="linenos">95</span></a>	<span class="k">return</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">tokenizer</span> <span class="ow">in</span> <span class="n">get_all_tokenizers</span><span class="p">()])</span>
</span></pre></div>


            <div class="docstring"><p>computes the sorted list of names of all tokenizers</p>
</div>


                </section>
                <section id="EVERY_TEST_TOKENIZERS">
                    <div class="attr variable">
            <span class="name">EVERY_TEST_TOKENIZERS</span><span class="annotation">: list[<a href="../../tokenization.html#MazeTokenizerModular">maze_dataset.tokenization.MazeTokenizerModular</a>]</span>        =
<input id="EVERY_TEST_TOKENIZERS-view-value" class="view-value-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
            <label class="view-value-button pdoc-button" for="EVERY_TEST_TOKENIZERS-view-value"></label><span class="default_value">[MazeTokenizerModular(prompt_sequencer=PromptSequencers.AOTP(coord_tokenizer=CoordTokenizers.UT(), adj_list_tokenizer=AdjListTokenizers.AdjListCoord(pre=False, post=True, shuffle_d0=True, edge_grouping=EdgeGroupings.Ungrouped(connection_token_ordinal=1), edge_subset=EdgeSubsets.ConnectionEdges(walls=False), edge_permuter=EdgePermuters.RandomCoords()), target_tokenizer=TargetTokenizers.Unlabeled(post=False), path_tokenizer=PathTokenizers.StepSequence(step_size=StepSizes.Singles(), step_tokenizers=(StepTokenizers.Coord(),), pre=False, intra=False, post=False))), MazeTokenizerModular(prompt_sequencer=PromptSequencers.AOTP(coord_tokenizer=CoordTokenizers.CTT(pre=True, intra=True, post=True), adj_list_tokenizer=AdjListTokenizers.AdjListCoord(pre=False, post=True, shuffle_d0=True, edge_grouping=EdgeGroupings.Ungrouped(connection_token_ordinal=1), edge_subset=EdgeSubsets.ConnectionEdges(walls=False), edge_permuter=EdgePermuters.RandomCoords()), target_tokenizer=TargetTokenizers.Unlabeled(post=False), path_tokenizer=PathTokenizers.StepSequence(step_size=StepSizes.Singles(), step_tokenizers=(StepTokenizers.Coord(),), pre=False, intra=False, post=False)))]</span>

        
    </div>
    <a class="headerlink" href="#EVERY_TEST_TOKENIZERS"></a>
    
    

                </section>
                <section id="all_tokenizers_set">
                            <input id="all_tokenizers_set-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@cache</div>

        <span class="def">def</span>
        <span class="name">all_tokenizers_set</span><span class="signature pdoc-code multiline">(<span class="return-annotation">) -> <span class="nb">set</span><span class="p">[</span><span class="n"><a href="../../tokenization.html#MazeTokenizerModular">maze_dataset.tokenization.MazeTokenizerModular</a></span><span class="p">]</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="all_tokenizers_set-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/understanding-search/maze-dataset/blob/1.3.0maze_dataset/tokenization/modular/all_tokenizers.py#L106-L109" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#all_tokenizers_set"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="all_tokenizers_set-107"><a href="#all_tokenizers_set-107"><span class="linenos">107</span></a><span class="nd">@cache</span>
</span><span id="all_tokenizers_set-108"><a href="#all_tokenizers_set-108"><span class="linenos">108</span></a><span class="k">def</span><span class="w"> </span><span class="nf">all_tokenizers_set</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">set</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]:</span>
</span><span id="all_tokenizers_set-109"><a href="#all_tokenizers_set-109"><span class="linenos">109</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Casts `get_all_tokenizers()` to a set.&quot;&quot;&quot;</span>
</span><span id="all_tokenizers_set-110"><a href="#all_tokenizers_set-110"><span class="linenos">110</span></a>	<span class="k">return</span> <span class="nb">set</span><span class="p">(</span><span class="n">get_all_tokenizers</span><span class="p">())</span>
</span></pre></div>


            <div class="docstring"><p>Casts <code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code> to a set.</p>
</div>


                </section>
                <section id="sample_all_tokenizers">
                            <input id="sample_all_tokenizers-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">sample_all_tokenizers</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">n</span><span class="p">:</span> <span class="nb">int</span></span><span class="return-annotation">) -> <span class="nb">list</span><span class="p">[</span><span class="n"><a href="../../tokenization.html#MazeTokenizerModular">maze_dataset.tokenization.MazeTokenizerModular</a></span><span class="p">]</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="sample_all_tokenizers-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/understanding-search/maze-dataset/blob/1.3.0maze_dataset/tokenization/modular/all_tokenizers.py#L118-L120" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#sample_all_tokenizers"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="sample_all_tokenizers-119"><a href="#sample_all_tokenizers-119"><span class="linenos">119</span></a><span class="k">def</span><span class="w"> </span><span class="nf">sample_all_tokenizers</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]:</span>
</span><span id="sample_all_tokenizers-120"><a href="#sample_all_tokenizers-120"><span class="linenos">120</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Samples `n` tokenizers from `get_all_tokenizers()`.&quot;&quot;&quot;</span>
</span><span id="sample_all_tokenizers-121"><a href="#sample_all_tokenizers-121"><span class="linenos">121</span></a>	<span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">get_all_tokenizers</span><span class="p">(),</span> <span class="n">n</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Samples <code>n</code> tokenizers from <code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code>.</p>
</div>


                </section>
                <section id="sample_tokenizers_for_test">
                            <input id="sample_tokenizers_for_test-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">sample_tokenizers_for_test</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="nb">list</span><span class="p">[</span><span class="n"><a href="../../tokenization.html#MazeTokenizerModular">maze_dataset.tokenization.MazeTokenizerModular</a></span><span class="p">]</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="sample_tokenizers_for_test-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/understanding-search/maze-dataset/blob/1.3.0maze_dataset/tokenization/modular/all_tokenizers.py#L123-L141" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#sample_tokenizers_for_test"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="sample_tokenizers_for_test-124"><a href="#sample_tokenizers_for_test-124"><span class="linenos">124</span></a><span class="k">def</span><span class="w"> </span><span class="nf">sample_tokenizers_for_test</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]:</span>
</span><span id="sample_tokenizers_for_test-125"><a href="#sample_tokenizers_for_test-125"><span class="linenos">125</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Returns a sample of size `n` of unique elements from `get_all_tokenizers()`,</span>
</span><span id="sample_tokenizers_for_test-126"><a href="#sample_tokenizers_for_test-126"><span class="linenos">126</span></a>
</span><span id="sample_tokenizers_for_test-127"><a href="#sample_tokenizers_for_test-127"><span class="linenos">127</span></a><span class="sd">	always including every element in `EVERY_TEST_TOKENIZERS`.</span>
</span><span id="sample_tokenizers_for_test-128"><a href="#sample_tokenizers_for_test-128"><span class="linenos">128</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="sample_tokenizers_for_test-129"><a href="#sample_tokenizers_for_test-129"><span class="linenos">129</span></a>	<span class="k">if</span> <span class="n">n</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="sample_tokenizers_for_test-130"><a href="#sample_tokenizers_for_test-130"><span class="linenos">130</span></a>		<span class="k">return</span> <span class="n">get_all_tokenizers</span><span class="p">()</span>
</span><span id="sample_tokenizers_for_test-131"><a href="#sample_tokenizers_for_test-131"><span class="linenos">131</span></a>
</span><span id="sample_tokenizers_for_test-132"><a href="#sample_tokenizers_for_test-132"><span class="linenos">132</span></a>	<span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">):</span>
</span><span id="sample_tokenizers_for_test-133"><a href="#sample_tokenizers_for_test-133"><span class="linenos">133</span></a>		<span class="n">err_msg</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;`n` must be at least </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">)</span><span class="w"> </span><span class="si">= }</span><span class="s2"> such that the sample can contain `EVERY_TEST_TOKENIZERS`.&quot;</span>
</span><span id="sample_tokenizers_for_test-134"><a href="#sample_tokenizers_for_test-134"><span class="linenos">134</span></a>		<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="sample_tokenizers_for_test-135"><a href="#sample_tokenizers_for_test-135"><span class="linenos">135</span></a>			<span class="n">err_msg</span><span class="p">,</span>
</span><span id="sample_tokenizers_for_test-136"><a href="#sample_tokenizers_for_test-136"><span class="linenos">136</span></a>		<span class="p">)</span>
</span><span id="sample_tokenizers_for_test-137"><a href="#sample_tokenizers_for_test-137"><span class="linenos">137</span></a>	<span class="n">sample</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MazeTokenizerModular</span><span class="p">]</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
</span><span id="sample_tokenizers_for_test-138"><a href="#sample_tokenizers_for_test-138"><span class="linenos">138</span></a>		<span class="n">_all_tokenizers_except_every_test_tokenizers</span><span class="p">(),</span>
</span><span id="sample_tokenizers_for_test-139"><a href="#sample_tokenizers_for_test-139"><span class="linenos">139</span></a>		<span class="n">n</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">),</span>
</span><span id="sample_tokenizers_for_test-140"><a href="#sample_tokenizers_for_test-140"><span class="linenos">140</span></a>	<span class="p">)</span>
</span><span id="sample_tokenizers_for_test-141"><a href="#sample_tokenizers_for_test-141"><span class="linenos">141</span></a>	<span class="n">sample</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">EVERY_TEST_TOKENIZERS</span><span class="p">)</span>
</span><span id="sample_tokenizers_for_test-142"><a href="#sample_tokenizers_for_test-142"><span class="linenos">142</span></a>	<span class="k">return</span> <span class="n">sample</span>
</span></pre></div>


            <div class="docstring"><p>Returns a sample of size <code>n</code> of unique elements from <code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code>,</p>

<p>always including every element in <code><a href="#EVERY_TEST_TOKENIZERS">EVERY_TEST_TOKENIZERS</a></code>.</p>
</div>


                </section>
                <section id="save_hashes">
                            <input id="save_hashes-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">save_hashes</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">parallelize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">) -> <span class="n">jaxtyping</span><span class="o">.</span><span class="n">UInt32</span><span class="p">[</span><span class="n">ndarray</span><span class="p">,</span> <span class="s1">&#39;n_tokens&#39;</span><span class="p">]</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="save_hashes-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/understanding-search/maze-dataset/blob/1.3.0maze_dataset/tokenization/modular/all_tokenizers.py#L144-L219" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#save_hashes"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="save_hashes-145"><a href="#save_hashes-145"><span class="linenos">145</span></a><span class="k">def</span><span class="w"> </span><span class="nf">save_hashes</span><span class="p">(</span>
</span><span id="save_hashes-146"><a href="#save_hashes-146"><span class="linenos">146</span></a>	<span class="n">path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="save_hashes-147"><a href="#save_hashes-147"><span class="linenos">147</span></a>	<span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="save_hashes-148"><a href="#save_hashes-148"><span class="linenos">148</span></a>	<span class="n">parallelize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="save_hashes-149"><a href="#save_hashes-149"><span class="linenos">149</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AllTokenizersHashesArray</span><span class="p">:</span>
</span><span id="save_hashes-150"><a href="#save_hashes-150"><span class="linenos">150</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;Computes, sorts, and saves the hashes of every member of `get_all_tokenizers()`.&quot;&quot;&quot;</span>
</span><span id="save_hashes-151"><a href="#save_hashes-151"><span class="linenos">151</span></a>	<span class="n">spinner</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="save_hashes-152"><a href="#save_hashes-152"><span class="linenos">152</span></a>		<span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">SpinnerContext</span><span class="p">,</span> <span class="n">spinner_chars</span><span class="o">=</span><span class="s2">&quot;square_dot&quot;</span><span class="p">)</span>
</span><span id="save_hashes-153"><a href="#save_hashes-153"><span class="linenos">153</span></a>		<span class="k">if</span> <span class="n">verbose</span>
</span><span id="save_hashes-154"><a href="#save_hashes-154"><span class="linenos">154</span></a>		<span class="k">else</span> <span class="n">NoOpContextManager</span>
</span><span id="save_hashes-155"><a href="#save_hashes-155"><span class="linenos">155</span></a>	<span class="p">)</span>
</span><span id="save_hashes-156"><a href="#save_hashes-156"><span class="linenos">156</span></a>
</span><span id="save_hashes-157"><a href="#save_hashes-157"><span class="linenos">157</span></a>	<span class="c1"># get all tokenizers</span>
</span><span id="save_hashes-158"><a href="#save_hashes-158"><span class="linenos">158</span></a>	<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="s2">&quot;getting all tokenizers...&quot;</span><span class="p">,</span> <span class="n">update_interval</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
</span><span id="save_hashes-159"><a href="#save_hashes-159"><span class="linenos">159</span></a>		<span class="n">all_tokenizers</span> <span class="o">=</span> <span class="n">get_all_tokenizers</span><span class="p">()</span>
</span><span id="save_hashes-160"><a href="#save_hashes-160"><span class="linenos">160</span></a>
</span><span id="save_hashes-161"><a href="#save_hashes-161"><span class="linenos">161</span></a>	<span class="c1"># compute hashes</span>
</span><span id="save_hashes-162"><a href="#save_hashes-162"><span class="linenos">162</span></a>	<span class="n">hashes_array_np64</span><span class="p">:</span> <span class="n">AllTokenizersHashesArray</span>
</span><span id="save_hashes-163"><a href="#save_hashes-163"><span class="linenos">163</span></a>	<span class="k">if</span> <span class="n">parallelize</span><span class="p">:</span>
</span><span id="save_hashes-164"><a href="#save_hashes-164"><span class="linenos">164</span></a>		<span class="n">n_cpus</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="save_hashes-165"><a href="#save_hashes-165"><span class="linenos">165</span></a>			<span class="n">parallelize</span> <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">parallelize</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
</span><span id="save_hashes-166"><a href="#save_hashes-166"><span class="linenos">166</span></a>		<span class="p">)</span>
</span><span id="save_hashes-167"><a href="#save_hashes-167"><span class="linenos">167</span></a>		<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span>  <span class="c1"># noqa: SIM117</span>
</span><span id="save_hashes-168"><a href="#save_hashes-168"><span class="linenos">168</span></a>			<span class="n">initial_value</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;using </span><span class="si">{</span><span class="n">n_cpus</span><span class="si">}</span><span class="s2"> processes to compute </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">all_tokenizers</span><span class="p">)</span><span class="si">}</span><span class="s2"> tokenizer hashes...&quot;</span><span class="p">,</span>
</span><span id="save_hashes-169"><a href="#save_hashes-169"><span class="linenos">169</span></a>			<span class="n">update_interval</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
</span><span id="save_hashes-170"><a href="#save_hashes-170"><span class="linenos">170</span></a>		<span class="p">):</span>
</span><span id="save_hashes-171"><a href="#save_hashes-171"><span class="linenos">171</span></a>			<span class="k">with</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">n_cpus</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
</span><span id="save_hashes-172"><a href="#save_hashes-172"><span class="linenos">172</span></a>				<span class="n">hashes_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="nb">hash</span><span class="p">,</span> <span class="n">all_tokenizers</span><span class="p">))</span>
</span><span id="save_hashes-173"><a href="#save_hashes-173"><span class="linenos">173</span></a>
</span><span id="save_hashes-174"><a href="#save_hashes-174"><span class="linenos">174</span></a>		<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="s2">&quot;converting hashes to numpy array...&quot;</span><span class="p">):</span>
</span><span id="save_hashes-175"><a href="#save_hashes-175"><span class="linenos">175</span></a>			<span class="n">hashes_array_np64</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hashes_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="save_hashes-176"><a href="#save_hashes-176"><span class="linenos">176</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="save_hashes-177"><a href="#save_hashes-177"><span class="linenos">177</span></a>		<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span>
</span><span id="save_hashes-178"><a href="#save_hashes-178"><span class="linenos">178</span></a>			<span class="n">initial_value</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;computing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">all_tokenizers</span><span class="p">)</span><span class="si">}</span><span class="s2"> tokenizer hashes...&quot;</span><span class="p">,</span>
</span><span id="save_hashes-179"><a href="#save_hashes-179"><span class="linenos">179</span></a>		<span class="p">):</span>
</span><span id="save_hashes-180"><a href="#save_hashes-180"><span class="linenos">180</span></a>			<span class="n">hashes_array_np64</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="save_hashes-181"><a href="#save_hashes-181"><span class="linenos">181</span></a>				<span class="p">[</span>
</span><span id="save_hashes-182"><a href="#save_hashes-182"><span class="linenos">182</span></a>					<span class="nb">hash</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>  <span class="c1"># uses stable hash</span>
</span><span id="save_hashes-183"><a href="#save_hashes-183"><span class="linenos">183</span></a>					<span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">all_tokenizers</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">)</span>
</span><span id="save_hashes-184"><a href="#save_hashes-184"><span class="linenos">184</span></a>				<span class="p">],</span>
</span><span id="save_hashes-185"><a href="#save_hashes-185"><span class="linenos">185</span></a>				<span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
</span><span id="save_hashes-186"><a href="#save_hashes-186"><span class="linenos">186</span></a>			<span class="p">)</span>
</span><span id="save_hashes-187"><a href="#save_hashes-187"><span class="linenos">187</span></a>
</span><span id="save_hashes-188"><a href="#save_hashes-188"><span class="linenos">188</span></a>	<span class="c1"># convert to correct dtype</span>
</span><span id="save_hashes-189"><a href="#save_hashes-189"><span class="linenos">189</span></a>	<span class="n">hashes_array</span><span class="p">:</span> <span class="n">AllTokenizersHashesArray</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="save_hashes-190"><a href="#save_hashes-190"><span class="linenos">190</span></a>		<span class="n">hashes_array_np64</span> <span class="o">%</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">AllTokenizersHashBitLength</span><span class="p">)</span>
</span><span id="save_hashes-191"><a href="#save_hashes-191"><span class="linenos">191</span></a>		<span class="k">if</span> <span class="n">AllTokenizersHashBitLength</span> <span class="o">&lt;</span> <span class="mi">64</span>  <span class="c1"># noqa: PLR2004</span>
</span><span id="save_hashes-192"><a href="#save_hashes-192"><span class="linenos">192</span></a>		<span class="k">else</span> <span class="n">hashes_array_np64</span>
</span><span id="save_hashes-193"><a href="#save_hashes-193"><span class="linenos">193</span></a>	<span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">AllTokenizersHashDtype</span><span class="p">)</span>
</span><span id="save_hashes-194"><a href="#save_hashes-194"><span class="linenos">194</span></a>
</span><span id="save_hashes-195"><a href="#save_hashes-195"><span class="linenos">195</span></a>	<span class="c1"># make sure there are no dupes</span>
</span><span id="save_hashes-196"><a href="#save_hashes-196"><span class="linenos">196</span></a>	<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="s2">&quot;sorting and checking for hash collisions...&quot;</span><span class="p">):</span>
</span><span id="save_hashes-197"><a href="#save_hashes-197"><span class="linenos">197</span></a>		<span class="n">sorted_hashes</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">hashes_array</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="save_hashes-198"><a href="#save_hashes-198"><span class="linenos">198</span></a>		<span class="k">if</span> <span class="n">sorted_hashes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">hashes_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="save_hashes-199"><a href="#save_hashes-199"><span class="linenos">199</span></a>			<span class="n">collisions</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="n">sorted_hashes</span><span class="p">[</span><span class="n">counts</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="save_hashes-200"><a href="#save_hashes-200"><span class="linenos">200</span></a>			<span class="n">n_collisions</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">hashes_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">sorted_hashes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="save_hashes-201"><a href="#save_hashes-201"><span class="linenos">201</span></a>			<span class="n">err_msg</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="save_hashes-202"><a href="#save_hashes-202"><span class="linenos">202</span></a>				<span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">n_collisions</span><span class="si">}</span><span class="s2"> tokenizer hash collisions: </span><span class="si">{</span><span class="n">collisions</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="save_hashes-203"><a href="#save_hashes-203"><span class="linenos">203</span></a>				<span class="s2">&quot;Report error to the developer to increase the hash size or otherwise update the tokenizer hashing size:</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="save_hashes-204"><a href="#save_hashes-204"><span class="linenos">204</span></a>				<span class="sa">f</span><span class="s2">&quot;https://github.com/understanding-search/maze-dataset/issues/new?labels=bug,tokenization&amp;title=Tokenizer+hash+collision+error&amp;body=</span><span class="si">{</span><span class="n">n_collisions</span><span class="si">}</span><span class="s2">+collisions+out+of+</span><span class="si">{</span><span class="n">hashes_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">+total+hashes&quot;</span><span class="p">,</span>
</span><span id="save_hashes-205"><a href="#save_hashes-205"><span class="linenos">205</span></a>			<span class="p">)</span>
</span><span id="save_hashes-206"><a href="#save_hashes-206"><span class="linenos">206</span></a>
</span><span id="save_hashes-207"><a href="#save_hashes-207"><span class="linenos">207</span></a>			<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="save_hashes-208"><a href="#save_hashes-208"><span class="linenos">208</span></a>				<span class="n">err_msg</span><span class="p">,</span>
</span><span id="save_hashes-209"><a href="#save_hashes-209"><span class="linenos">209</span></a>			<span class="p">)</span>
</span><span id="save_hashes-210"><a href="#save_hashes-210"><span class="linenos">210</span></a>
</span><span id="save_hashes-211"><a href="#save_hashes-211"><span class="linenos">211</span></a>	<span class="c1"># save and return</span>
</span><span id="save_hashes-212"><a href="#save_hashes-212"><span class="linenos">212</span></a>	<span class="k">with</span> <span class="n">spinner</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="s2">&quot;saving hashes...&quot;</span><span class="p">,</span> <span class="n">update_interval</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
</span><span id="save_hashes-213"><a href="#save_hashes-213"><span class="linenos">213</span></a>		<span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="save_hashes-214"><a href="#save_hashes-214"><span class="linenos">214</span></a>			<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="s2">&quot;MazeTokenizerModular_hashes.npz&quot;</span>
</span><span id="save_hashes-215"><a href="#save_hashes-215"><span class="linenos">215</span></a>		<span class="n">np</span><span class="o">.</span><span class="n">savez_compressed</span><span class="p">(</span>
</span><span id="save_hashes-216"><a href="#save_hashes-216"><span class="linenos">216</span></a>			<span class="n">path</span><span class="p">,</span>
</span><span id="save_hashes-217"><a href="#save_hashes-217"><span class="linenos">217</span></a>			<span class="n">hashes</span><span class="o">=</span><span class="n">sorted_hashes</span><span class="p">,</span>
</span><span id="save_hashes-218"><a href="#save_hashes-218"><span class="linenos">218</span></a>		<span class="p">)</span>
</span><span id="save_hashes-219"><a href="#save_hashes-219"><span class="linenos">219</span></a>
</span><span id="save_hashes-220"><a href="#save_hashes-220"><span class="linenos">220</span></a>	<span class="k">return</span> <span class="n">sorted_hashes</span>
</span></pre></div>


            <div class="docstring"><p>Computes, sorts, and saves the hashes of every member of <code><a href="#get_all_tokenizers">get_all_tokenizers()</a></code>.</p>
</div>


                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>