name: All Tokenizer Checks

on:
  push:
    paths:
      - 'maze_dataset/utils.py' # temporary
      - 'maze_dataset/token_utils.py' # temporary
      - 'maze_dataset/constants.py'
      - 'maze_dataset/tokenization/*.py'
      - 'maze_dataset/tokenization/modular/*.py'
      - 'maze_dataset/tokenization/modular/MazeTokenizerModular_tested.fst'
      - 'notebooks/demo_mazetokenizermodular.ipynb'
      - 'tests/all_tokenizers/*.py'
      - 'pyproject.toml' # on new version or update deps
      - '.github/workflows/all-tok-checks.yml' # changing this file
      - '.lastversion' # on new release
  workflow_dispatch:
    inputs:
      n_to_test:
        description: 'Number of tokenizers to test'
        required: false
        default: 10000
        type: number
      pytest_parallel:
        description: '1 to parallelize tests with -n auto, to run without parallelization'
        required: false
        default: 1
        type: number

jobs:
  all_tok_test:
    name: All Tokenizer Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
        
      - name: set up uv
        run: curl -LsSf https://astral.sh/uv/install.sh | sh

      - name: tokenizer fst check (check all, this will take a while)
        run: |
          make tokenizer-fst-check

      - name: long tokenizer tests
        run: |
          N_TO_TEST=${{ github.event.inputs.n_to_test || '10000' }}
          PYTEST_PARALLEL=${{ github.event.inputs.pytest_parallel || '1' }}
          make tokenizer-test-long NUM_TOKENIZERS_TO_TEST=$N_TO_TEST PYTEST_PARALLEL=$PYTEST_PARALLEL